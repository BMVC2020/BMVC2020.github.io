<!DOCTYPE html>
<html lang="en-GB">


<!-- Mirrored from bmvc2019.org/programme/detailed-programme/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 25 Feb 2020 09:57:28 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
	<meta charset='UTF-8'>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="profile" href="http://gmpg.org/xfn/11">
		<title>Detailed Programme &ndash; BMVC 2019 Cardiff</title>

<!-- This site is optimized with the Yoast SEO plugin v11.7 - https://yoast.com/wordpress/plugins/seo/ -->
<link rel="canonical" href="index.html" />
<meta property="og:locale" content="en_GB" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Detailed Programme &ndash; BMVC 2019 Cardiff" />
<meta property="og:description" content="The full BMVC 2019 Programme (including paper abstracts) can be downloaded here. Monday 9th September 12:00 &#8212; 13:15 &nbsp;&nbsp;Registration 13:15 &#8212; 13:30 &nbsp;&nbsp;Welcome 13:30 &#8212; 15:30 &nbsp;&nbsp;Tutorial Sir Martin Evans Building Computational Face AnalysisProf. Michel Valstar (University of Nottingham) 15:30 &#8212; 16:15 &nbsp;&nbsp;Tea Break SU, Great Hall 16:15 &#8212; 18:15 &hellip;" />
<meta property="og:url" content="index.html" />
<meta property="og:site_name" content="BMVC 2019 Cardiff" />
<meta property="og:image" content="../../wp-content/uploads/2019/09/snapinc-150x150.png" />
<meta property="og:image:secure_url" content="../../wp-content/uploads/2019/09/snapinc-150x150.png" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:description" content="The full BMVC 2019 Programme (including paper abstracts) can be downloaded here. Monday 9th September 12:00 &#8212; 13:15 &nbsp;&nbsp;Registration 13:15 &#8212; 13:30 &nbsp;&nbsp;Welcome 13:30 &#8212; 15:30 &nbsp;&nbsp;Tutorial Sir Martin Evans Building Computational Face AnalysisProf. Michel Valstar (University of Nottingham) 15:30 &#8212; 16:15 &nbsp;&nbsp;Tea Break SU, Great Hall 16:15 &#8212; 18:15 [&hellip;]" />
<meta name="twitter:title" content="Detailed Programme &ndash; BMVC 2019 Cardiff" />
<meta name="twitter:site" content="@bmvc2019" />
<meta name="twitter:image" content="../../wp-content/uploads/2019/09/snapinc-150x150.png" />
<meta name="twitter:creator" content="@bmvc2019" />
<script type='application/ld+json' class='yoast-schema-graph yoast-schema-graph--main'>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://bmvc2019.org/#organization","name":"BMVC 2019","url":"https://bmvc2019.org/","sameAs":["https://twitter.com/bmvc2019"],"logo":{"@type":"ImageObject","@id":"https://bmvc2019.org/#logo","url":"https://bmvc2019.org/wp-content/uploads/2018/10/Logo_Red_Full_Raster.png","width":621,"height":391,"caption":"BMVC 2019"},"image":{"@id":"https://bmvc2019.org/#logo"}},{"@type":"WebSite","@id":"https://bmvc2019.org/#website","url":"https://bmvc2019.org/","name":"BMVC 2019","publisher":{"@id":"https://bmvc2019.org/#organization"},"potentialAction":{"@type":"SearchAction","target":"https://bmvc2019.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://bmvc2019.org/programme/detailed-programme/#primaryimage","url":"https://bmvc2019.org/wp-content/uploads/2019/09/snapinc.png","width":2133,"height":2133},{"@type":"WebPage","@id":"https://bmvc2019.org/programme/detailed-programme/#webpage","url":"https://bmvc2019.org/programme/detailed-programme/","inLanguage":"en-GB","name":"Detailed Programme &ndash; BMVC 2019 Cardiff","isPartOf":{"@id":"https://bmvc2019.org/#website"},"primaryImageOfPage":{"@id":"https://bmvc2019.org/programme/detailed-programme/#primaryimage"},"datePublished":"2019-07-25T16:10:00+00:00","dateModified":"2019-09-23T10:53:54+00:00"}]}</script>
<!-- / Yoast SEO plugin. -->

<link rel='dns-prefetch' href='http://maxcdn.bootstrapcdn.com/' />
<link rel='dns-prefetch' href='http://fonts.googleapis.com/' />
<link rel='dns-prefetch' href='http://s.w.org/' />
<link rel="alternate" type="application/rss+xml" title="BMVC 2019 Cardiff &raquo; Feed" href="../../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="BMVC 2019 Cardiff &raquo; Comments Feed" href="../../comments/feed/index.html" />
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/11\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/11\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/bmvc2019.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.9.8"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55358,56760,9792,65039],[55358,56760,8203,9792,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel='stylesheet' id='wp-block-library-css'  href='../../wp-content/plugins/gutenberg/build/block-library/style9199.css?ver=1549297593' type='text/css' media='all' />
<link rel='stylesheet' id='font-awesome-5-css'  href='../../wp-content/plugins/themeisle-companion/obfx_modules/gutenberg-blocks/assets/fontawesome/css/all.min5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='font-awesome-4-shims-css'  href='../../wp-content/plugins/themeisle-companion/obfx_modules/gutenberg-blocks/assets/fontawesome/css/v4-shims.min5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='themeisle-block_styles-css'  href='../../wp-content/plugins/themeisle-companion/vendor/codeinwp/gutenberg-blocks/build/style5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='advgb_custom_styles-css'  href='../../wp-content/uploads/advgb/custom_styles5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='dashicons-css'  href='../../wp-includes/css/dashicons.min5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='advgb_blocks_styles_min-css'  href='../../wp-content/plugins/advanced-gutenberg/assets/css/blocks_styles/blocks.min5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='hestia-clients-bar-css'  href='../../wp-content/plugins/themeisle-companion/obfx_modules/companion-legacy/assets/css/hestia/clients-bar5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='obfx-module-pub-css-menu-icons-0-css'  href='../../../maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.minf71b.css?ver=2.8.0' type='text/css' media='all' />
<link rel='stylesheet' id='obfx-module-pub-css-menu-icons-1-css'  href='../../wp-content/plugins/themeisle-companion/obfx_modules/menu-icons/css/publicf71b.css?ver=2.8.0' type='text/css' media='all' />
<link rel='stylesheet' id='cookie-consent-style-css'  href='../../wp-content/plugins/uk-cookie-consent/assets/css/style5010.css?ver=4.9.8' type='text/css' media='all' />
<link rel='stylesheet' id='bootstrap-css'  href='../../wp-content/themes/hestia/assets/bootstrap/css/bootstrap.min20b9.css?ver=1.0.2' type='text/css' media='all' />
<link rel='stylesheet' id='hestia-font-sizes-css'  href='../../wp-content/themes/hestia/assets/css/font-sizes.min747d.css?ver=2.4.5' type='text/css' media='all' />
<link rel='stylesheet' id='font-awesome-css'  href='../../wp-content/themes/hestia/assets/font-awesome/css/font-awesome.min20b9.css?ver=1.0.2' type='text/css' media='all' />
<link rel='stylesheet' id='hestia_style-css'  href='../../wp-content/themes/hestia/style.min747d.css?ver=2.4.5' type='text/css' media='all' />
<style id='hestia_style-inline-css' type='text/css'>
.hestia-top-bar, .hestia-top-bar .widget.widget_shopping_cart .cart_list {
			background-color: #363537
		}
		.hestia-top-bar .widget .label-floating input[type=search]:-webkit-autofill {
			-webkit-box-shadow: inset 0 0 0px 9999px #363537
		}.hestia-top-bar, .hestia-top-bar .widget .label-floating input[type=search], .hestia-top-bar .widget.widget_search form.form-group:before, .hestia-top-bar .widget.widget_product_search form.form-group:before, .hestia-top-bar .widget.widget_shopping_cart:before {
			color: #ffffff
		} 
		.hestia-top-bar .widget .label-floating input[type=search]{
			-webkit-text-fill-color:#ffffff !important 
		}.hestia-top-bar a, .hestia-top-bar .top-bar-nav li a {
			color: #ffffff
		}.hestia-top-bar a:hover, .hestia-top-bar .top-bar-nav li a:hover {
			color: #eeeeee
		}
	
		a, 
		.navbar .dropdown-menu li:hover > a,
		.navbar .dropdown-menu li:focus > a,
		.navbar .dropdown-menu li:active > a,
		.navbar .navbar-nav > li .dropdown-menu li:hover > a,
		body:not(.home) .navbar-default .navbar-nav > .active:not(.btn) > a,
		body:not(.home) .navbar-default .navbar-nav > .active:not(.btn) > a:hover,
		body:not(.home) .navbar-default .navbar-nav > .active:not(.btn) > a:focus,
		a:hover, 
		.card-blog a.moretag:hover, 
		.card-blog a.more-link:hover, 
		.widget a:hover,
		.has-accent-color {
		    color:#e91e63;
		}
		
		.pagination span.current, .pagination span.current:focus, .pagination span.current:hover {
			border-color:#e91e63
		}
		
		button,
		button:hover,
		.woocommerce .track_order button[type="submit"],
		.woocommerce .track_order button[type="submit"]:hover,
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit,
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit:hover,
		input[type="button"],
		input[type="button"]:hover,
		input[type="submit"],
		input[type="submit"]:hover,
		input#searchsubmit, 
		.pagination span.current, 
		.pagination span.current:focus, 
		.pagination span.current:hover,
		.btn.btn-primary,
		.btn.btn-primary:link,
		.btn.btn-primary:hover, 
		.btn.btn-primary:focus, 
		.btn.btn-primary:active, 
		.btn.btn-primary.active, 
		.btn.btn-primary.active:focus, 
		.btn.btn-primary.active:hover,
		.btn.btn-primary:active:hover, 
		.btn.btn-primary:active:focus, 
		.btn.btn-primary:active:hover,
		.hestia-sidebar-open.btn.btn-rose,
		.hestia-sidebar-close.btn.btn-rose,
		.hestia-sidebar-open.btn.btn-rose:hover,
		.hestia-sidebar-close.btn.btn-rose:hover,
		.hestia-sidebar-open.btn.btn-rose:focus,
		.hestia-sidebar-close.btn.btn-rose:focus,
		.label.label-primary,
		.hestia-work .portfolio-item:nth-child(6n+1) .label,
		.nav-cart .nav-cart-content .widget .buttons .button,
		.has-accent-background-color {
		    background-color: #e91e63;
		}
		
		@media (max-width: 768px) { 
	
			.navbar-default .navbar-nav>li>a:hover,
			.navbar-default .navbar-nav>li>a:focus,
			.navbar .navbar-nav .dropdown .dropdown-menu li a:hover,
			.navbar .navbar-nav .dropdown .dropdown-menu li a:focus,
			.navbar button.navbar-toggle:hover,
			.navbar .navbar-nav li:hover > a i {
			    color: #e91e63;
			}
		}
		
		body:not(.woocommerce-page) button:not([class^="fl-"]):not(.hestia-scroll-to-top):not(.navbar-toggle):not(.close),
		body:not(.woocommerce-page) .button:not([class^="fl-"]):not(hestia-scroll-to-top):not(.navbar-toggle):not(.add_to_cart_button),
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit,
		input[type="submit"], 
		input[type="button"], 
		.btn.btn-primary,
		.widget_product_search button[type="submit"],
		.hestia-sidebar-open.btn.btn-rose,
		.hestia-sidebar-close.btn.btn-rose,
		.everest-forms button[type=submit].everest-forms-submit-button {
		    -webkit-box-shadow: 0 2px 2px 0 rgba(233,30,99,0.14),0 3px 1px -2px rgba(233,30,99,0.2),0 1px 5px 0 rgba(233,30,99,0.12);
		    box-shadow: 0 2px 2px 0 rgba(233,30,99,0.14),0 3px 1px -2px rgba(233,30,99,0.2),0 1px 5px 0 rgba(233,30,99,0.12);
		}
		
		.card .header-primary, .card .content-primary,
		.everest-forms button[type=submit].everest-forms-submit-button {
		    background: #e91e63;
		}
		
		body:not(.woocommerce-page) .button:not([class^="fl-"]):not(.hestia-scroll-to-top):not(.navbar-toggle):not(.add_to_cart_button):hover,
		body:not(.woocommerce-page) button:not([class^="fl-"]):not(.hestia-scroll-to-top):not(.navbar-toggle):not(.close):hover,
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit:hover,
		input[type="submit"]:hover,
		input[type="button"]:hover,
		input#searchsubmit:hover, 
		.widget_product_search button[type="submit"]:hover,
		.pagination span.current, 
		.btn.btn-primary:hover, 
		.btn.btn-primary:focus, 
		.btn.btn-primary:active, 
		.btn.btn-primary.active, 
		.btn.btn-primary:active:focus, 
		.btn.btn-primary:active:hover, 
		.hestia-sidebar-open.btn.btn-rose:hover,
		.hestia-sidebar-close.btn.btn-rose:hover,
		.pagination span.current:hover,
		.everest-forms button[type=submit].everest-forms-submit-button:hover,
 		.everest-forms button[type=submit].everest-forms-submit-button:focus,
 		.everest-forms button[type=submit].everest-forms-submit-button:active {
			-webkit-box-shadow: 0 14px 26px -12px rgba(233,30,99,0.42),0 4px 23px 0 rgba(0,0,0,0.12),0 8px 10px -5px rgba(233,30,99,0.2);
		    box-shadow: 0 14px 26px -12px rgba(233,30,99,0.42),0 4px 23px 0 rgba(0,0,0,0.12),0 8px 10px -5px rgba(233,30,99,0.2);
			color: #fff;
		}
		
		.form-group.is-focused .form-control {
			background-image: -webkit-gradient(linear,left top, left bottom,from(#e91e63),to(#e91e63)),-webkit-gradient(linear,left top, left bottom,from(#d2d2d2),to(#d2d2d2));
			background-image: -webkit-linear-gradient(linear,left top, left bottom,from(#e91e63),to(#e91e63)),-webkit-linear-gradient(linear,left top, left bottom,from(#d2d2d2),to(#d2d2d2));
			background-image: linear-gradient(linear,left top, left bottom,from(#e91e63),to(#e91e63)),linear-gradient(linear,left top, left bottom,from(#d2d2d2),to(#d2d2d2));
		}
		
		.navbar:not(.navbar-transparent) li:not(.btn):hover > a,
		.navbar li.on-section:not(.btn) > a, 
		.navbar.full-screen-menu.navbar-transparent li:not(.btn):hover > a,
		.navbar.full-screen-menu .navbar-toggle:hover,
		.navbar:not(.navbar-transparent) .nav-cart:hover, 
		.navbar:not(.navbar-transparent) .hestia-toggle-search:hover {
				color:#e91e63}
		
		.header-filter-gradient { 
			background: linear-gradient(45deg, rgba(211,16,62,1) 0%, rgb(255,44,41) 100%); 
		}
		.has-header-gradient-color { color: #d3103e; }
		.has-header-gradient-background-color { background-color: #d3103e; }
		 
		.has-background-color-color { color: #E5E5E5; }
		.has-background-color-background-color { background-color: #E5E5E5; }
		
.btn.btn-primary:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item), input[type="submit"]:not(.search-submit), body:not(.woocommerce-account) .woocommerce .button.woocommerce-Button, .woocommerce .product button.button, .woocommerce .product button.button.alt, .woocommerce .product #respond input#submit, .woocommerce-cart .blog-post .woocommerce .cart-collaterals .cart_totals .checkout-button, .woocommerce-checkout #payment #place_order, .woocommerce-account.woocommerce-page button.button, .woocommerce .track_order button[type="submit"], .nav-cart .nav-cart-content .widget .buttons .button, .woocommerce a.button.wc-backward, body.woocommerce .wccm-catalog-item a.button, body.woocommerce a.wccm-button.button, form.woocommerce-form-coupon button.button, div.wpforms-container .wpforms-form button[type=submit].wpforms-submit, div.woocommerce a.button.alt, div.woocommerce table.my_account_orders .button, .btn.colored-button, .btn.btn-left, .btn.btn-right, .btn:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item):not(.hestia-sidebar-open):not(.hestia-sidebar-close){ padding-top:15px;  padding-bottom:15px;  padding-left:33px;  padding-right:33px; }
.btn.btn-primary:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item), input[type="submit"]:not(.search-submit), body:not(.woocommerce-account) .woocommerce .button.woocommerce-Button, .woocommerce .product button.button, .woocommerce .product button.button.alt, .woocommerce .product #respond input#submit, .woocommerce-cart .blog-post .woocommerce .cart-collaterals .cart_totals .checkout-button, .woocommerce-checkout #payment #place_order, .woocommerce-account.woocommerce-page button.button, .woocommerce .track_order button[type="submit"], .nav-cart .nav-cart-content .widget .buttons .button, .woocommerce a.button.wc-backward, body.woocommerce .wccm-catalog-item a.button, body.woocommerce a.wccm-button.button, form.woocommerce-form-coupon button.button, div.wpforms-container .wpforms-form button[type=submit].wpforms-submit, div.woocommerce a.button.alt, div.woocommerce table.my_account_orders .button, input[type="submit"].search-submit, .hestia-view-cart-wrapper .added_to_cart.wc-forward, .woocommerce-product-search button, .woocommerce-cart .actions .button, #secondary div[id^=woocommerce_price_filter] .button, .woocommerce div[id^=woocommerce_widget_cart].widget .buttons .button, .searchform input[type=submit], .searchform button, .search-form:not(.media-toolbar-primary) input[type=submit], .search-form:not(.media-toolbar-primary) button, .woocommerce-product-search input[type=submit], .btn.colored-button, .btn.btn-left, .btn.btn-right, .btn:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item):not(.hestia-sidebar-open):not(.hestia-sidebar-close){border-radius:3px;}
@media (min-width: 769px){
			.page-header.header-small .hestia-title,
			.page-header.header-small .title,
			h1.hestia-title.title-in-content,
			.main article.section .has-title-font-size {
				font-size: 42px;
			}}

		.page-template-builder-fullwidth-std .header > .elementor {
			padding-top: 70px;
		}

</style>
<link rel='stylesheet' id='hestia_fonts-css'  href='https://fonts.googleapis.com/css?family=Roboto%3A300%2C400%2C500%2C700%7CRoboto+Slab%3A400%2C700&amp;subset=latin%2Clatin-ext&amp;ver=2.4.5' type='text/css' media='all' />
<link rel='stylesheet' id='wpgdprc.css-css'  href='../../wp-content/plugins/wp-gdpr-compliance/assets/css/front004f.css?ver=1562162887' type='text/css' media='all' />
<style id='wpgdprc.css-inline-css' type='text/css'>

            div.wpgdprc .wpgdprc-switch .wpgdprc-switch-inner:before { content: 'Yes'; }
            div.wpgdprc .wpgdprc-switch .wpgdprc-switch-inner:after { content: 'No'; }
        
</style>
<script type='text/javascript' src='../../wp-includes/js/jquery/jqueryb8ff.js?ver=1.12.4'></script>
<script type='text/javascript' src='../../wp-includes/js/jquery/jquery-migrate.min330a.js?ver=1.4.1'></script>
<script type='text/javascript' src='../../wp-content/uploads/hm_custom_css_js/custom0a32.js?ver=1542878598'></script>
<link rel='https://api.w.org/' href='../../wp-json/index.html' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="../../xmlrpc0db0.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../../wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 4.9.8" />
<link rel='shortlink' href='../../index0c99.html?p=3311' />
<link rel="alternate" type="application/json+oembed" href="../../wp-json/oembed/1.0/embeda06e.json?url=https%3A%2F%2Fbmvc2019.org%2Fprogramme%2Fdetailed-programme%2F" />
<link rel="alternate" type="text/xml+oembed" href="../../wp-json/oembed/1.0/embedeae5?url=https%3A%2F%2Fbmvc2019.org%2Fprogramme%2Fdetailed-programme%2F&amp;format=xml" />
                       <style id="ctcc-css" type="text/css" media="screen">
				#catapult-cookie-bar {
					box-sizing: border-box;
					max-height: 0;
					opacity: 0;
					z-index: 99999;
					overflow: hidden;
					color: #ddd;
					position: fixed;
					left: 0;
					bottom: 0;
					width: 100%;
					background-color: #464646;
				}
				#catapult-cookie-bar a {
					color: #fff;
				}
				#catapult-cookie-bar .x_close span {
					background-color: ;
				}
				button#catapultCookie {
					background:;
					color: ;
					border: 0; padding: 6px 9px; border-radius: 3px;
				}
				#catapult-cookie-bar h3 {
					color: #ddd;
				}
				.has-cookie-bar #catapult-cookie-bar {
					opacity: 1;
					max-height: 999px;
					min-height: 30px;
				}</style>
<style type="text/css" media="all">

</style>
<link rel="icon" href="../../wp-content/uploads/2018/10/cropped-Logo_Red_Square_Raster-1-32x32.png" sizes="32x32" />
<link rel="icon" href="../../wp-content/uploads/2018/10/cropped-Logo_Red_Square_Raster-1-192x192.png" sizes="192x192" />
<link rel="apple-touch-icon-precomposed" href="../../wp-content/uploads/2018/10/cropped-Logo_Red_Square_Raster-1-180x180.png" />
<meta name="msapplication-TileImage" content="https://bmvc2019.org/wp-content/uploads/2018/10/cropped-Logo_Red_Square_Raster-1-270x270.png" />

<!-- BEGIN ExactMetrics v5.3.9 Universal Analytics - https://exactmetrics.com/ -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','../../../www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-127549873-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- END ExactMetrics Universal Analytics -->
		<style type="text/css" id="wp-custom-css">
			/* Smaller page headers */
.page-header.header-small .container{
padding-top:  125px !important;
padding-bottom: 10px !important; 
}

/* Increase subtitle size on main page */
#carousel-hestia-generic > div > div > div > div > div.container > div > div > span{
	font-size: 32px
}


/* Use Cardiff Red rather than pink as page header colour */
.header-filter-gradient{
	background-color: #d3103e !important;
	background-image: none;
}


/* Responsive logo sizing stuff */
@media only screen and (min-width: 400px) {
body > div.wrapper > header > nav > div > div.navbar-header > div.title-logo-wrapper > a > img{
	max-height: 75px;
}
}

.btn-primary {
	background-color: #be0e38 !important;
}


/* Increase padding at bottom of posts/pages.  */
.blog-post .section-text {
    padding-bottom: 20px !important;
}


.advgb-testimonial-name{
	margin-bottom: 0 !important;
}

.advgb-testimonial-position{
	text-transform: none !important;
	font-size: 18px !important;
}

.clients-bar-item{
	width:25%
}

#clients{
	padding: 0;
}

#tpbr_topbar{
	display: none;
}




		</style>
	</head>

<body class="page-template-default page page-id-3311 page-child parent-pageid-85 wp-custom-logo blog-post header-layout-default">
		<div class="wrapper  default ">
		<header class="header ">
			<div style="display: none"></div>		<nav class="navbar navbar-default navbar-fixed-top  hestia_left navbar-not-transparent">
						<div class="container">
						<div class="navbar-header">
			<div class="title-logo-wrapper">
				<a class="navbar-brand" href="../../index.html"
						title="BMVC 2019 Cardiff">
					<img src="../../wp-content/uploads/2018/10/cropped-Logo_Red_Full_Raster.png" alt="BMVC 2019 Cardiff"></a>
			</div>
								<div class="navbar-toggle-wrapper">
						<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navigation">
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="sr-only">Toggle Navigation</span>
			</button>
					</div>
				</div>
		<div id="main-navigation" class="collapse navbar-collapse"><ul id="menu-main-nav" class="nav navbar-nav"><li id="menu-item-167" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-167"><a title="Home" href="../../index.html">Home</a></li>
<li id="menu-item-174" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-174"><a title="Dates" href="../../dates/index.html">Dates</a></li>
<li id="menu-item-551" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-551 dropdown"><a title="Authors" href="../../authors/call-for-papers-2/index.html" class="dropdown-toggle">Authors <span class="caret-wrap"><span class="caret"></span></span></a>
<ul role="menu" class="dropdown-menu">
	<li id="menu-item-552" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-552"><a title="Call for Papers" href="../../authors/call-for-papers-2/index.html">Call for Papers</a></li>
	<li id="menu-item-553" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-553"><a title="Submit your Paper" href="../../authors/submit-your-paper-2/index.html">Submit your Paper</a></li>
	<li id="menu-item-827" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-827"><a title="Accepted Papers" href="../../authors/accepted-papers-2/index.html">Accepted Papers</a></li>
	<li id="menu-item-857" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-857"><a title="Presentation Instructions" href="../../authors/presentation-instructions-2/index.html">Presentation Instructions</a></li>
</ul>
</li>
<li id="menu-item-190" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-190 dropdown"><a title="Attending" href="../../attending/travel-info/index.html" class="dropdown-toggle">Attending <span class="caret-wrap"><span class="caret"></span></span></a>
<ul role="menu" class="dropdown-menu">
	<li id="menu-item-3407" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3407"><a title="Attendance Information" href="../../attendance-information/index.html">Attendance Information</a></li>
	<li id="menu-item-308" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-308"><a title="Travel Info" href="../../attending/travel-info/index.html">Travel Info</a></li>
	<li id="menu-item-188" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-188"><a title="Venue" href="../../attending/venue/index.html">Venue</a></li>
	<li id="menu-item-189" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-189"><a title="Accommodation" href="../../attending/accomodation/index.html">Accommodation</a></li>
	<li id="menu-item-187" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-187"><a title="Registration" href="../../attending/registration/index.html">Registration</a></li>
	<li id="menu-item-837" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-837"><a title="Student Bursaries" href="../../student-bursaries/index.html">Student Bursaries</a></li>
	<li id="menu-item-661" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-661"><a title="Conference Banquet" href="../../attending/registration/conference-banquet/index.html">Conference Banquet</a></li>
</ul>
</li>
<li id="menu-item-422" class="menu-item menu-item-type-post_type menu-item-object-page current-page-ancestor current-menu-ancestor current-menu-parent current-page-parent current_page_parent current_page_ancestor menu-item-has-children menu-item-422 dropdown"><a title="Programme" href="../index.html" class="dropdown-toggle">Programme <span class="caret-wrap"><span class="caret"></span></span></a>
<ul role="menu" class="dropdown-menu">
	<li id="menu-item-3456" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3456"><a title="Best Paper Awards" href="../best-paper-awards/index.html">Best Paper Awards</a></li>
	<li id="menu-item-3414" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3414"><a title="Outstanding Reviewers" href="../../outstanding-reviewers/index.html">Outstanding Reviewers</a></li>
	<li id="menu-item-3310" class="menu-item menu-item-type-post_type menu-item-object-page current-page-ancestor current-page-parent menu-item-3310"><a title="Programme at a glance" href="../index.html">Programme at a glance</a></li>
	<li id="menu-item-3330" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-3311 current_page_item menu-item-3330 active"><a title="Detailed Programme" href="index.html">Detailed Programme</a></li>
	<li id="menu-item-673" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-673"><a title="Keynote Speakers" href="../keynote-speakers/index.html">Keynote Speakers</a></li>
	<li id="menu-item-695" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-695"><a title="Workshops" href="../../workshops/index.html">Workshops</a></li>
	<li id="menu-item-423" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-423"><a title="Tutorials" href="../tutorials/index.html">Tutorials</a></li>
</ul>
</li>
<li id="menu-item-303" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-303 dropdown"><a title="People" href="../../people/organisers-2/index.html" class="dropdown-toggle">People <span class="caret-wrap"><span class="caret"></span></span></a>
<ul role="menu" class="dropdown-menu">
	<li id="menu-item-175" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-175"><a title="Organisers" href="../../people/organisers-2/index.html">Organisers</a></li>
</ul>
</li>
<li id="menu-item-173" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-173"><a title="Sponsorship" href="../../sponsorship/index.html">Sponsorship</a></li>
</ul></div>			</div>
					</nav>
				</header>
<div id="primary" class="boxed-layout-header page-header header-small" data-parallax="active" ><div class="container"><div class="row"><div class="col-md-10 col-md-offset-1 text-center"><h1 class="hestia-title ">Detailed Programme</h1></div></div></div><div class="header-filter header-filter-gradient"></div></div><div class="main  main-raised ">
		<div class="blog-post ">
		<div class="container">
			

	<article id="post-3311" class="section section-text">
		<div class="row">
						<div class="col-md-8 page-content-wrap  col-md-offset-2">
<p> The full program will be confirmed closer to the date </p>
<!--				
<p>The full BMVC 2019 Programme (including paper abstracts) <a href="../../wp-content/uploads/2019/09/bmvc_book_final.pdf">can be downloaded here</a>.</p>



<script>
function toggleList(lid){
    jQuery(lid).slideToggle();
}
</script>

<h2>Monday 9<sup>th</sup> September</h2>
<div>
<p>
<b>12:00 &#8212; 13:15 &nbsp;&nbsp;Registration</b>
</p>
</div>
<div>
<p>
<b>13:15 &#8212; 13:30 &nbsp;&nbsp;Welcome</b>
</p>
</div>
<div>
<p>
<b>13:30 &#8212; 15:30 &nbsp;&nbsp;Tutorial</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p><b>Computational Face Analysis</b><br />Prof. Michel Valstar (University of Nottingham)</p>
</div>
</p>
</div>
<div>
<p>
<b>15:30 &#8212; 16:15 &nbsp;&nbsp;Tea Break</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>16:15 &#8212; 18:15 &nbsp;&nbsp;Tutorial</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p><b>Robust Visual Search and Matching</b><br /> Prof. John Collomosse (University of Surrey), Prof. Ondrej Chum (Czech Technical University in Prague), and Miroslaw Bober (University of Surrey)</p>
</div>
</p>
</div>
<div>
<p>
<b>19:00 &#8212; late &nbsp;&nbsp;Reception</b>
<i>Viriamu Jones Gallery</i>
<div style="margin-left:40px; padding-top: 0px">
<p>Sponsored by Snap Inc. <br /> <img src='../../wp-content/uploads/2019/09/snapinc-150x150.png' width='100px' height='100px' /></p>
</div>
</p>
</div>
<hr />
<h2>Tuesday 10<sup>th</sup> September</h2>
<div>
<p>
<b>08:00 &#8212; 08:45 &nbsp;&nbsp;Registration</b>
</p>
</div>
<div>
<p>
<b>08:45 &#8212; 09:00 &nbsp;&nbsp;Welcome</b>
</p>
</div>
<div>
<p>
<b>09:00 &#8212; 10:00 &nbsp;&nbsp;Keynote</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p><b>4D Vision in the Wild</b> <br /> Prof. Adrian Hilton (University of Surrey)<br />Sponsored by Facebook</p>
</div>
</p>
</div>
<div>
<p>
<b>10:00 &#8212; 11:00 &nbsp;&nbsp;Spotlights (Session 1)</b>
<i>Sir Martin Evans Building</i>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_1'>
<p>
<b>1. <a href='../../wp-content/uploads/papers/0018-paper.pdf'> Adversarial View-Consistent Learning for Monocular Depth Estimation</a></b>  <br />
    Yixuan Liu (Tsinghua University); Yuwang Wang (Microsoft Research); Shengjin Wang (Tsinghua University) <br />
            </p>

<p>
<b>2. <a href='../../wp-content/uploads/papers/0258-paper.pdf'> Joint Spatial and Layer Attention for Convolutional Networks</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0258-supplementary.pdf'>[Supplementary]</a> <br />
    Tony Joseph (University of Ontario Institute of Technology); Konstantinos Derpanis (Ryerson University); Faisal Qureshi (University of Ontario Institute of Technology) <br />
            </p>

<p>
<b>3. <a href='../../wp-content/uploads/papers/0333-paper.pdf'> A Less Biased Evaluation of Out-of-distribution Sample Detectors</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0333-supplementary.zip'>[Supplementary]</a> <br />
    Alireza Shafaei (The University of British Columbia); Mark Schmidt (University of British Columbia); Jim Little (University of British Columbia) <br />
            </p>

<p>
<b>4. <a href='../../wp-content/uploads/papers/0403-paper.pdf'> Unmasking the Devil in the Details:What Works for Deep Facial Action Coding?</a></b>  <br />
    Koichiro Niinuma (Fujitsu Laboratories of America, Inc.); Laszlo Jeni (Carnegie Mellon University); Jeffrey Cohn (University of Pittsburgh); Itir Onal Ertugrul (Carnegie Mellon University) <br />
            </p>

<p>
<b>5. <a href='../../wp-content/uploads/papers/0406-paper.pdf'> Multi-Weight Partial Domain Adaptation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0406-supplementary.zip'>[Supplementary]</a> <br />
    Jian Hu (Shanghai Jiaotong University); Hongya Tuo (Shanghai Jiaotong University); Chao Wang (Shanghai Jiaotong University); Lingfeng Qiao (Shanhai Jiaotong University); Haowen Zhong (Shanghai Jiaotong University); Zhongliang Jing (Shanghai Jiaotong University) <br />
            </p>

<p>
<b>6. <a href='../../wp-content/uploads/papers/0469-paper.pdf'> Text Recognition using local correlation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0469-supplementary.zip'>[Supplementary]</a> <br />
    Yujia Li (Institute of Information Engineering, Chinese Academy of Sciences); Hongchao Gao (Institute of Information Engineering, Chinese Academy of Sciences); Xi Wang (Institute of Information Engineering, Chinese Academy of Sciences); Jizhong Han (Institute of Information Engineering, Chinese Academy of Sciences); Ruixuan Li (Huazhong University of Science and Technology) <br />
            </p>

<p>
<b>7. <a href='../../wp-content/uploads/papers/0499-paper.pdf'> DetectFusion: Detecting and Segmenting Both Known and Unknown Dynamic Objects in Real-time SLAM</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0499-supplementary.zip'>[Supplementary]</a> <br />
    Ryo Hachiuma (Keio University); Christian Pirchheim (Graz University of Technology); Dieter Schmalstieg (Graz University of Technology); Hideo Saito (Keio University) <br />
            </p>

<p>
<b>8. <a href='../../wp-content/uploads/papers/0564-paper.pdf'> Bilinear Siamese Networks with Background Suppression for Visual Object Tracking</a></b>  <br />
    Hankyeol Lee (Korea Advanced Institute of Science and Technology); Seokeon Choi (Korea Advanced Institute of Science and Technology); Youngeun Kim (Korea Advanced Institute of Science and Technology); Changick Kim (Korea Advanced Institute of Science and Technology) <br />
            </p>

<p>
<b>9. <a href='../../wp-content/uploads/papers/0629-paper.pdf'> Adversarial Examples for Handcrafted Features</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0629-supplementary.pdf'>[Supplementary]</a> <br />
    Muhammad Latif Anjum (NUST); Zohaib Ali (NUST); Wajahat Hussain (NUST &#8211; SEECS) <br />
            </p>

<p>
<b>10. <a href='../../wp-content/uploads/papers/0690-paper.pdf'> One-shot Face Reenactment</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0690-supplementary.zip'>[Supplementary]</a> <br />
    Cheng Li (SenseTime Research); Yunxuan Zhang (SenseTime Research); Yue He (SenseTime Research); Siwei Zhang (SenseTime Research); Ziwei Liu (The Chinese University of Hong Kong); Chen Change Loy (Nanyang Technological University) <br />
            </p>

<p>
<b>11. <a href='../../wp-content/uploads/papers/0728-paper.pdf'> Learning to Focus and Track Extreme Climate Events</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0728-supplementary.pdf'>[Supplementary]</a> <br />
    Sookyung Kim (Lawrence Livermore National Laboratory); Sunghyun Park (Korea University); Sunghyo Chung (Korea University); Joonseok Lee (Google Research); Yunsung Lee (Korea University); Hyojin Kim (LLNL); Prabhat (Lawrence Berkeley National Laboratory); Jaegul Choo (Korea University) <br />
            </p>

<p>
<b>12. <a href='../../wp-content/uploads/papers/0740-paper.pdf'> Revisiting Residual Networks with Nonlinear Shortcuts</a></b>  <br />
    Chaoning Zhang (KAIST); Francois Rameau (KAIST); Seokju Lee (KAIST); Junsik Kim (KAIST); Philipp Benz (KAIST); Dawit Mureja Argaw (KAIST); Jean-Charles Bazin (KAIST); In So Kweon (KAIST) <br />
            </p>

<p>
<b>13. <a href='../../wp-content/uploads/papers/0931-paper.pdf'> Unified 2D and 3D Hand Pose Estimation from a Single Visible or X-ray Image</a></b>  <br />
    Akila Pemasiri (Queensland University of Technology); Kien Nguyen Thanh (Queensland University of Technology); Sridha Sridharan (Queensland University of Technology); Clinton  Fookes (Queensland University of Technology) <br />
            </p>

<p>
<b>14. <a href='../../wp-content/uploads/papers/0981-paper.pdf'> Perspective-n-Learned-Point: Pose Estimation from Relative Depth</a></b>  <br />
    Nathan Piasco (Univ. Bourgogne Franche-Comte); Désiré Sidibé (Université de Bourgogne); Cedric Demonceaux (Univ. Bourgogne Franche-Comte); Valérie Gouet-Brunet (LASTIG/IGN) <br />
            </p>

<p>
<b>15. <a href='../../wp-content/uploads/papers/1049-paper.pdf'> Joint Multi-view Texture Super-resolution and Intrinsic Decomposition</a></b>  <br />
    Wei Dong (Carnegie Mellon University); Vagia Tsiminaki (ETH Zurich); Martin R. Oswald (ETH Zurich); Marc Pollefeys (ETH Zurich / Microsoft) <br />
            </p>

<p>
<b>16. <a href='../../wp-content/uploads/papers/1114-paper.pdf'> Class-Distinct and Class-Mutual Image Generation with GANs</a></b>  <br />
    Takuhiro Kaneko (The University of Tokyo); Yoshitaka Ushiku (The University of Tokyo); Tatsuya Harada (The University of Tokyo / RIKEN) <br />
            </p>

</div>
</div>
<div>
<p>
<b>11:00 &#8212; 11:45 &nbsp;&nbsp;Tea Break</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>11:45 &#8212; 13:15 &nbsp;&nbsp;Oral Presentations: Deep Learning for Vision (Session 1)</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p>Chair: Xianghua Xie <br />Sponsored by Microsoft</p>
</div>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_2'>
<p>
<b>17. <a href='../../wp-content/uploads/papers/0061-paper.pdf'> Guided Zoom: Questioning Network Evidence for Fine-grained Classification</a></b>  <br />
    Sarah Bargal (Boston University); Andrea Zunino (Istituto Italiano di Tecnologia); Vitali Petsiuk (Boston University); Jianming Zhang (Adobe Research); Kate Saenko (Boston University); Vittorio Murino (Istituto Italiano di Tecnologia); Stan Sclaroff (Boston University) <br />
            </p>

<p>
<b>18. <a href='../../wp-content/uploads/papers/0384-paper.pdf'> Embodied Vision-and-Language Navigation with Dynamic Convolutional Filters</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0384-supplementary.zip'>[Supplementary]</a> <br />
    Federico Landi (University of Modena and Reggio Emilia); Lorenzo Baraldi (University of Modena and Reggio Emilia); Massimiliano Corsini (University of Modena and Reggio Emilia); Rita Cucchiara (University of Modena and Reggio Emilia) <br />
            </p>

<p>
<b>19. <a href='../../wp-content/uploads/papers/0588-paper.pdf'> Accurate and Compact Convolutional Neural Networks with Trained Binarization</a></b>  <br />
    Zhe Xu (City University of Hong Kong); Ray Cheung (City University of Hong Kong) <br />
            </p>

<p>
<b>20. <a href='../../wp-content/uploads/papers/0655-paper.pdf'> Show, Infer and Tell: Contextual Inference for Creative Captioning</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0655-supplementary.pdf'>[Supplementary]</a> <br />
    Ankit Khare (University of Texas at Arlington); Manfred Huber (University of Texas at Arlington) <br />
            </p>

<p>
<b>21. <a href='../../wp-content/uploads/papers/0938-paper.pdf'> Push for Quantization: Deep Fisher Hashing</a></b>  <br />
    Yunqiang Li (Delft University of Technology); Wenjie Pei (Tencent); yufei zha (Air Force Engineering University); Jan van Gemert (Delft University of Technology) <br />
            </p>

<p>
<b>22. <a href='../../wp-content/uploads/papers/1073-paper.pdf'> RecNets: Channel-wise Recurrent Convolutional Neural Networks</a></b>  <br />
    George Retsinas (National Technical University of Athens); Athena Elafrou (National Technical University of Athens); Georgios Goumas (	National Technical University of Athens); Petros Maragos (National Technical University of Athens) <br />
            </p>

</div>
</div>
<div>
<p>
<b>13:15 &#8212; 14:00 &nbsp;&nbsp;Lunch</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>14:00 &#8212; 16:15 &nbsp;&nbsp;Posters (Session 1)</b>
<i>SU, Great Hall</i>
<br /><a href='#/' onclick="toggleList('#session_3')">[Toggle Poster List]</a>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_3'>
<p>
<b>23. <a href='../../wp-content/uploads/papers/0274-paper.pdf'> Pixel-Wise Confidences for Stereo Disparities Using Recurrent Neural Networks</a></b>  <br />
    Muhammad Shahzeb Khan Gul (Fraunhofer IIS); Michel Bätz (Fraunhofer IIS); Joachim Keinert (Fraunhofer IIS) <br />
            </p>

<p>
<b>24. <a href='../../wp-content/uploads/papers/0329-paper.pdf'> Pan-tilt-zoom SLAM for Sports Videos</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0329-supplementary.pdf'>[Supplementary]</a> <br />
    Jikai Lu (Zhejiang University); Jianhui Chen (University of British Columbia); Jim Little (University of British Columbia, Canada) <br />
            </p>

<p>
<b>25. <a href='../../wp-content/uploads/papers/0450-paper.pdf'> An Evaluation of Feature Matchers for Fundamental Matrix Estimation</a></b>  <br />
    JiaWang Bian (The University of Adelaide); Yu-Huan Wu (Nankai University); Ji Zhao (TuSimple); Yun Liu (Nankai University); Le Zhang (Institute for Infocomm Research，Agency for Science, Technology and Research (ASTAR)); Ming-Ming Cheng (Nankai University); Ian Reid (University of Adelaide) <br />
            </p>

<p>
<b>26. <a href='../../wp-content/uploads/papers/0533-paper.pdf'> A Simple Direct Solution to the Perspective-Three-Point Problem</a></b>  <br />
    Gaku Nakano (NEC Corporation) <br />
            </p>

<p>
<b>27. <a href='../../wp-content/uploads/papers/0629-paper.pdf'> Adversarial Examples for Handcrafted Features</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0629-supplementary.pdf'>[Supplementary]</a> <br />
    Muhammad Latif Anjum (NUST); Zohaib Ali (NUST); Wajahat Hussain (NUST &#8211; SEECS) <br />
            </p>

<p>
<b>28. <a href='../../wp-content/uploads/papers/0156-paper.pdf'> Physical Cue based Depth-Sensing by Color Coding with Deaberration Network</a></b>  <br />
    Nao Mishima (Toshiba Research and Development Center); Tatsuo Kozakaya (Toshiba); Akihisa Moriya (Toshiba); Ryuzo Okdata (Toshiba); Shinsaku Hiura (University of Hyogo) <br />
            </p>

<p>
<b>29. <a href='../../wp-content/uploads/papers/1004-paper.pdf'> Merge-SfM: Merging Partial Reconstructions</a></b>  <br />
    Meiling Fang (Fraunhofer IOSB); Thomas Pollok (Fraunhofer IOSB); Chengchao Qu (Fraunhofer IOSB) <br />
            </p>

<p>
<b>30. <a href='../../wp-content/uploads/papers/0337-paper.pdf'> Semi-supervised Macromolecule Structural Classification in Cellular Electron Cryo-Tomograms using 3D Autoencoding Classifier</a></b>  <br />
    Siyuan Liu (Carnegie Mellon University); Xuefeng Du (Xi&#x27;an Jiaotong University); Rong Xi (Carnegie Mellon University); Fuya Xu (Carnegie Mellon University); Xiangrui Zeng (Carnegie Mellon University); Bo Zhou (Yale University); Min Xu (Carnegie Mellon University) <br />
            </p>

<p>
<b>31. <a href='../../wp-content/uploads/papers/0431-paper.pdf'> Large scale joint semantic re-localisation and scene understanding via globally unique instance coordinate regression</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0431-supplementary.zip'>[Supplementary]</a> <br />
    Ignas Budvytis (Department of Engineering, University of Cambridge); Marvin Teichmann (Machine Intelligence Laboratory, Cambridge University Department of Engineering); Tomas Vojir (University of Cambridge); Roberto Cipolla (University of Cambridge) <br />
            </p>

<p>
<b>32. <a href='../../wp-content/uploads/papers/0974-paper.pdf'> Matching Features without Descriptors: Implicitly Matched Interest Points</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0974-supplementary.zip'>[Supplementary]</a> <br />
    Titus Cieslewski (University of Zurich &amp; ETH Zurich); Michael Bloesch (Deepmind); Davide Scaramuzza (University of Zurich &amp; ETH Zurich) <br />
            </p>

<p>
<b>33. <a href='../../wp-content/uploads/papers/0331-paper.pdf'> Triangulation: Why Optimize?</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0331-supplementary.zip'>[Supplementary]</a> <br />
    Seong Hun Lee (University of Zaragoza); Javier Civera (Universidad de Zaragoza) <br />
            </p>

<p>
<b>34. <a href='../../wp-content/uploads/papers/0392-paper.pdf'> Single-view Object Shape Reconstruction Using Deep Shape Prior and Silhouette</a></b>  <br />
    Kejie Li (University of Adelaide); Ravi Garg (University of Adelaide); Ming Cai (The University of Adelaide); Ian Reid (University of Adelaide) <br />
            </p>

<p>
<b>35. <a href='../../wp-content/uploads/papers/0452-paper.pdf'> Learning Embedding of 3D models with Quadric Loss</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0452-supplementary.pdf'>[Supplementary]</a> <br />
    Nitin Agarwal (Department of Computer Science, UC-Irvine); Sungeui Yoon (Korea Advanced Institute of Science and Technology); M Gopi (University of California, Irvine) <br />
            </p>

<p>
<b>36. <a href='../../wp-content/uploads/papers/0568-paper.pdf'> Probabilistic Reconstruction Networks for 3D Shape Inference from a Single Image</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0568-supplementary.zip'>[Supplementary]</a> <br />
    Roman Klokov (Inria); Jakob Verbeek (Inria); Edmond Boyer (Inria) <br />
            </p>

<p>
<b>37. <a href='../../wp-content/uploads/papers/0816-paper.pdf'> Optimal Multi-view Correction of Local Affine Frames</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0816-supplementary.pdf'>[Supplementary]</a> <br />
    Iván Eichhardt (MTA SZTAKI); Dániel Baráth (MTA SZTAKI, CMP Prague) <br />
            </p>

<p>
<b>38. <a href='../../wp-content/uploads/papers/0018-paper.pdf'> Adversarial View-Consistent Learning for Monocular Depth Estimation</a></b>  <br />
    Yixuan Liu (Tsinghua University); Yuwang Wang (Microsoft Research); Shengjin Wang (Tsinghua University) <br />
            </p>

<p>
<b>39. <a href='../../wp-content/uploads/papers/0125-paper.pdf'> Few-Shot Viewpoint Estimation</a></b>  <br />
    Hung-Yu Tseng (University of California, Merced); Shalini De Mello (NVIDIA Research); Jonathan Tremblay (NVIDIA); Sifei Liu (NVIDIA); Stan Birchfield (Clemson University); Ming-Hsuan Yang (University of California at Merced); Jan Kautz (NVIDIA) <br />
            </p>

<p>
<b>40. <a href='../../wp-content/uploads/papers/0199-paper.pdf'> Differentiable Fixed-Rank Regularisation using Bilinear Parameterisation</a></b>  <br />
    Marcus Valtonen Örnhag (Lund University); Carl Olsson (Lund University); Anders Heyden (LTH) <br />
            </p>

<p>
<b>41. <a href='../../wp-content/uploads/papers/0233-paper.pdf'> Mitigating the Hubness Problem for Zero-Shot Learning of 3D Objects</a></b>  <br />
    Ali Cheraghian (Australian National University); Shafin Rahman (Australian National University); Dylan Campbell (Australian National University); Lars Petersson (Data61/CSIRO) <br />
            </p>

<p>
<b>42. <a href='../../wp-content/uploads/papers/0327-paper.pdf'> Optimising 3D-CNN Design towards Human Pose Estimation on Low Power Devices</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0327-supplementary.zip'>[Supplementary]</a> <br />
    Manolis Vasileiadis (Imperial College London); Christos-Savvas Bouganis (Imperial College London); Georgios Stavropoulos (Centre for Research and Technology, Hellas, Information Technologies Institute); Dimitrios Tzovaras (Centre for Research and Technology, Hellas) <br />
            </p>

<p>
<b>43. <a href='../../wp-content/uploads/papers/0499-paper.pdf'> DetectFusion: Detecting and Segmenting Both Known and Unknown Dynamic Objects in Real-time SLAM</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0499-supplementary.zip'>[Supplementary]</a> <br />
    Ryo Hachiuma (Keio University); Christian Pirchheim (Graz University of Technology); Dieter Schmalstieg (Graz University of Technology); Hideo Saito (Keio University) <br />
            </p>

<p>
<b>44. <a href='../../wp-content/uploads/papers/0644-paper.pdf'> DublinCity: Annotated LiDAR Point Cloud and its Applications</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0644-supplementary-0.pdf'>[Supplementary 1]</a> <a style='font-size: 12px' href='../../wp-content/uploads/papers/0644-supplementary-1.mp4'>[Supplementary 2]</a>  <br />
    S M Iman Zolanvari (Trinity College Dublin); Susana Ruano (Trinity College Dublin); Aakanksha Rana (Trinity College Dublin); Alan Cummins (Trinity College Dublin); Rogério Eduardo da Silva (University of Houston-Victoria); Morteza Rahbar (CAAD, ITA, ETH Zurich); Aljosa Smolic (Trinity College Dublin) <br />
            </p>

<p>
<b>45. <a href='../../wp-content/uploads/papers/0653-paper.pdf'> Single Image 3D Hand Reconstruction with Mesh Convolutions</a></b>  <br />
    Dominik Kulon (Imperial College London); Haoyang Wang (Imperial College London); Alp Guler (Ariel AI,  Imperial College London); Michael Bronstein (Imperial College London); Stefanos Zafeiriou (Imperial College London) <br />
            </p>

<p>
<b>46. <a href='../../wp-content/uploads/papers/0710-paper.pdf'> MocapNET: Ensemble of SNN Encoders for 3D Human Pose Estimation in RGB Images</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0710-supplementary.zip'>[Supplementary]</a> <br />
    Ammar Qammaz (CSD-UOC and ICS-FORTH); Antonis Argyros (CSD-UOC and ICS-FORTH) <br />
            </p>

<p>
<b>47. <a href='../../wp-content/uploads/papers/0932-paper.pdf'> An Evaluation of Feature Encoding Techniques for Non-Rigid and Rigid 3D Point Cloud Retrieval</a></b>  <br />
    Sindhu Hegde (KLE Technological University); Shankar Gangisetty (KLE Technological University) <br />
            </p>

<p>
<b>48. <a href='../../wp-content/uploads/papers/0981-paper.pdf'> Perspective-n-Learned-Point: Pose Estimation from Relative Depth</a></b>  <br />
    Nathan Piasco (Univ. Bourgogne Franche-Comte); Désiré Sidibé (Université de Bourgogne); Cedric Demonceaux (Univ. Bourgogne Franche-Comte); Valérie Gouet-Brunet (LASTIG/IGN) <br />
            </p>

<p>
<b>49. <a href='../../wp-content/uploads/papers/1049-paper.pdf'> Joint Multi-view Texture Super-resolution and Intrinsic Decomposition</a></b>  <br />
    Wei Dong (Carnegie Mellon University); Vagia Tsiminaki (ETH Zurich); Martin R. Oswald (ETH Zurich); Marc Pollefeys (ETH Zurich / Microsoft) <br />
            </p>

<p>
<b>50. <a href='../../wp-content/uploads/papers/1217-paper.pdf'> Learning Depth-aware Heatmaps for 3D Human Pose Estimation in the Wild</a></b>  <br />
    Zerui Chen (Chinese Academy of Sciences); Yiru Guo (Beihang University); Yan Huang (Institute of Automation, Chinese Academy of Sciences); Liang Wang (NLPR, China) <br />
            </p>

<p>
<b>51. <a href='../../wp-content/uploads/papers/1039-paper.pdf'> DwNet: Dense warp-based network for pose-guided human video generation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1039-supplementary.zip'>[Supplementary]</a> <br />
    Polina Zablotskaia (University of British Columbia); Aliaksandr Siarohin (University of Trento); Leonid Sigal (University of British Columbia); Bo Zhao (University of British Columbia) <br />
            </p>

<p>
<b>52. <a href='../../wp-content/uploads/papers/1232-paper.pdf'> Annotation-free Quality Estimation of Food Grains using Deep Neural Network</a></b>  <br />
    Akankshya Kar (Samsung Research Institute Bangalore); Prakhar Kulshreshtha (Samsung Research Institute Bangalore); Ayush Agrawal (Samsung Research Institute Bangalore); Sandeep Palakkal (Samsung Electronics); Lokesh Boregowda (	Samsung Research Institute Bangalore) <br />
            </p>

<p>
<b>53. <a href='../../wp-content/uploads/papers/0384-paper.pdf'> Embodied Vision-and-Language Navigation with Dynamic Convolutional Filters</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0384-supplementary.zip'>[Supplementary]</a> <br />
    Federico Landi (University of Modena and Reggio Emilia); Lorenzo Baraldi (University of Modena and Reggio Emilia); Massimiliano Corsini (University of Modena and Reggio Emilia); Rita Cucchiara (University of Modena and Reggio Emilia) <br />
            </p>

<p>
<b>54. <a href='../../wp-content/uploads/papers/0588-paper.pdf'> Accurate and Compact Convolutional Neural Networks with Trained Binarization</a></b>  <br />
    Zhe Xu (City University of Hong Kong); Ray Cheung (City University of Hong Kong) <br />
            </p>

<p>
<b>55. <a href='../../wp-content/uploads/papers/0655-paper.pdf'> Show, Infer and Tell: Contextual Inference for Creative Captioning</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0655-supplementary.pdf'>[Supplementary]</a> <br />
    Ankit Khare (University of Texas at Arlington); Manfred Huber (University of Texas at Arlington) <br />
            </p>

<p>
<b>56. <a href='../../wp-content/uploads/papers/0717-paper.pdf'> Differentiable Unrolled Alternating Direction Method of Multipliers for OneNet</a></b>  <br />
    Zoltán Milacski (Eötvös Loránd University); Barnabas Poczos (Carnegie Mellon University); Andras Lorincz (Eötvös Loránd University) <br />
            </p>

<p>
<b>57. <a href='../../wp-content/uploads/papers/0821-paper.pdf'> Graph-based Knowledge Distillation by Multi-head Attention Network</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0821-supplementary.pdf'>[Supplementary]</a> <br />
    Seunghyun Lee (Inha University); Byung Cheol Song (Inha University) <br />
            </p>

<p>
<b>58. <a href='../../wp-content/uploads/papers/0938-paper.pdf'> Push for Quantization: Deep Fisher Hashing</a></b>  <br />
    Yunqiang Li (Delft University of Technology); Wenjie Pei (Tencent); yufei zha (Air Force Engineering University); Jan van Gemert (Delft University of Technology) <br />
            </p>

<p>
<b>59. <a href='../../wp-content/uploads/papers/1007-paper.pdf'> Addressing Data Bias Problems for Chest X-ray Image Report Generation</a></b>  <br />
    Philipp Harzig (University of Augsburg); Yan-Ying Chen (FX Pal); Francine Chen (FX Palo Alto Laboratory); Rainer Lienhart (Universitat Augsburg) <br />
            </p>

<p>
<b>60. <a href='../../wp-content/uploads/papers/1073-paper.pdf'> RecNets: Channel-wise Recurrent Convolutional Neural Networks</a></b>  <br />
    George Retsinas (National Technical University of Athens); Athena Elafrou (National Technical University of Athens); Georgios Goumas (	National Technical University of Athens); Petros Maragos (National Technical University of Athens) <br />
            </p>

<p>
<b>61. <a href='../../wp-content/uploads/papers/0120-paper.pdf'> Pose from Shape: Deep Pose Estimation for Arbitrary 3D Objects</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0120-supplementary.pdf'>[Supplementary]</a> <br />
    Yang Xiao (École des ponts ParisTech); Xuchong Qiu (École des Ponts ParisTech); Pierre-Alain Langlois (École des Ponts ParisTech); Mathieu Aubry (École des ponts ParisTech); Renaud Marlet (École des Ponts ParisTech) <br />
            </p>

<p>
<b>62. <a href='../../wp-content/uploads/papers/0121-paper.pdf'> XNOR-Net++: Improved binary neural networks</a></b>  <br />
    Adrian Bulat (Samsung AI Center, Cambridge); Georgios Tzimiropoulos (Samsung AI Centre, Cambridge) <br />
            </p>

<p>
<b>63. <a href='../../wp-content/uploads/papers/0214-paper.pdf'> Curriculum based Dropout Discriminator for Domain Adaptation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0214-supplementary.zip'>[Supplementary]</a> <br />
    Vinod Kurmi (IIT Kanpur); Vipul Bajaj (IIT Kanpur); Vinay Namboodiri (IIT Kanpur); K. S. Venkatesh (IIT Kanpur) <br />
            </p>

<p>
<b>64. <a href='../../wp-content/uploads/papers/0258-paper.pdf'> Joint Spatial and Layer Attention for Convolutional Networks</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0258-supplementary.pdf'>[Supplementary]</a> <br />
    Tony Joseph (University of Ontario Institute of Technology); Konstantinos Derpanis (Ryerson University); Faisal Qureshi (University of Ontario Institute of Technology) <br />
            </p>

<p>
<b>65. <a href='../../wp-content/uploads/papers/0286-paper.pdf'> Directed-Weighting Group Lasso For Eltwise Blocked CNN Pruning</a></b>  <br />
    Ke Zhan (Beijing University Of Technology); Shimiao Jiang (Alibaba, Inc.); Yu Bai (JD.com, Inc.); Yi Li (JD.com, Inc) <br />
            </p>

<p>
<b>66. <a href='../../wp-content/uploads/papers/0335-paper.pdf'> Camera Style and Identity Disentangling Network for Person Re-identification</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0335-supplementary.pdf'>[Supplementary]</a> <br />
    Ruochen Zheng (Huazhong University of Science and Technology); Lerenhan Li (Huazhong University of Science and Technology); Chuchu Han (Huazhong University of Science and Technology); Changxin Gao (Huazhong University of Science and Technology); Nong Sang (School of Automation, Huazhong University of Science and Technology) <br />
            </p>

<p>
<b>67. <a href='../../wp-content/uploads/papers/0350-paper.pdf'> Pseudo-Labeling Curriculum for Unsupervised Domain Adaptation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0350-supplementary.pdf'>[Supplementary]</a> <br />
    Jaehoon Choi (Korea Advanced Institute of Science and Technology); Minki Jeong (Korea Advanced Institute of Science and Technology); Taekyung Kim (Korea Advanced Institute of Science and Technology); Changick Kim (Korea Advanced Institute of Science and Technology) <br />
            </p>

<p>
<b>68. <a href='../../wp-content/uploads/papers/0369-paper.pdf'> BioFaceNet: Deep Biophysical Face Image Interpretation</a></b>  <br />
    Sarah Alotaibi (University of York); William Smith (University of York) <br />
            </p>

<p>
<b>69. <a href='../../wp-content/uploads/papers/0406-paper.pdf'> Multi-Weight Partial Domain Adaptation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0406-supplementary.zip'>[Supplementary]</a> <br />
    Jian Hu (Shanghai Jiaotong University); Hongya Tuo (Shanghai Jiaotong University); Chao Wang (Shanghai Jiaotong University); Lingfeng Qiao (Shanhai Jiaotong University); Haowen Zhong (Shanghai Jiaotong University); Zhongliang Jing (Shanghai Jiaotong University) <br />
            </p>

<p>
<b>70. <a href='../../wp-content/uploads/papers/0443-paper.pdf'> Semantically-Aware Attentive Neural Embeddings for 2D Long-Term Visual Localization</a></b>  <br />
    Zachary Seymour (SRI International); Karan Sikka (SRI International); Han-Pang Chiu (SRI International); Supun Samarasekera (SRI International); Rakesh Kumar (SRI International) <br />
            </p>

<p>
<b>71. <a href='../../wp-content/uploads/papers/0456-paper.pdf'> EPNAS: Efficient Progressive Neural Architecture Search</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0456-supplementary.pdf'>[Supplementary]</a> <br />
    Yanqi Zhou (Google); Peng Wang (Baidu USA LLC.) <br />
            </p>

<p>
<b>72. <a href='../../wp-content/uploads/papers/0559-paper.pdf'> Batch-wise Logit-Similarity: Generalizing Logit-Squeezing and Label-Smoothing</a></b>  <br />
    Ali Shafahi (University of Maryland); Mohammad Amin Ghiasi (University of Maryland); Mahyar Najibi (University of Maryland); Furong Huang (University of Maryland); John Dickerson (University of Maryland); Tom Goldstein (University of Maryland) <br />
            </p>

<p>
<b>73. <a href='../../wp-content/uploads/papers/0574-paper.pdf'> Scrutinizing and De-Biasing Intuitive Physics with Neural Stethoscopes</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0574-supplementary.zip'>[Supplementary]</a> <br />
    Fabian Fuchs (Oxford Robotics Insitute); Oliver Groth (Oxford Robotics Insitute); Adam Kosiorek (University of Oxford); Alex Bewley (Google); Markus Wulfmeier (DeepMind); Andrea Vedaldi (University of Oxford); Ingmar Posner (University of Oxford) <br />
            </p>

<p>
<b>74. <a href='../../wp-content/uploads/papers/0583-paper.pdf'> MixConv: Mixed Depthwise Convolutional Kernels</a></b>  <br />
    Mingxing Tan (Google Brain); Quoc Le (Google Brain) <br />
            </p>

<p>
<b>75. <a href='../../wp-content/uploads/papers/0597-paper.pdf'> Look and Modify: Modification Networks for Image Captioning</a></b>  <br />
    Fawaz Sammani (Multimedia University); Mahmoud Elsayed (Multimedia University) <br />
            </p>

<p>
<b>76. <a href='../../wp-content/uploads/papers/0609-paper.pdf'> Ordinal Pooling</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0609-supplementary.pdf'>[Supplementary]</a> <br />
    Adrien Deliege (University of Liege); Ashwani Kumar (University of Sheffield); Maxime Istasse (UCLouvain, ICTEAM, ELEN, ISPGroup); Christophe De Vleeschouwer (Université Catholique de Louvain); Marc Van Droogenbroeck (University of Liege) <br />
            </p>

<p>
<b>77. <a href='../../wp-content/uploads/papers/0675-paper.pdf'> Defending against adversarial examples using defense kernel network</a></b>  <br />
    Yuying Hao (TBSI, Tsinghua); Tuanhui Li (Tsinghua University); Yong Jiang (Tsinghua University); Xuanye Cheng (SenseTime Research); Li Li (Graduate School at Shenzhen, Tsinghua University) <br />
            </p>

<p>
<b>78. <a href='../../wp-content/uploads/papers/0690-paper.pdf'> One-shot Face Reenactment</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0690-supplementary.zip'>[Supplementary]</a> <br />
    Cheng Li (SenseTime Research); Yunxuan Zhang (SenseTime Research); Yue He (SenseTime Research); Siwei Zhang (SenseTime Research); Ziwei Liu (The Chinese University of Hong Kong); Chen Change Loy (Nanyang Technological University) <br />
            </p>

<p>
<b>79. <a href='../../wp-content/uploads/papers/0734-paper.pdf'> Predicting Visual Memory Schemas with Variational Autoencoders</a></b>  <br />
    Cameron Kyle-Davidson (University of York); Adrian Bors (University of York); Karla Evans (University of York) <br />
            </p>

<p>
<b>80. <a href='../../wp-content/uploads/papers/0740-paper.pdf'> Revisiting Residual Networks with Nonlinear Shortcuts</a></b>  <br />
    Chaoning Zhang (KAIST); Francois Rameau (KAIST); Seokju Lee (KAIST); Junsik Kim (KAIST); Philipp Benz (KAIST); Dawit Mureja Argaw (KAIST); Jean-Charles Bazin (KAIST); In So Kweon (KAIST) <br />
            </p>

<p>
<b>81. <a href='../../wp-content/uploads/papers/0790-paper.pdf'> PMC-GANs: Generating Multi-Scale High-Quality Pedestrian with Multimodal Cascaded GANs</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0790-supplementary-0.mp4'>[Supplementary 1]</a> <a style='font-size: 12px' href='../../wp-content/uploads/papers/0790-supplementary-1.zip'>[Supplementary 2]</a>  <br />
    Jie Wu (China Electronics Technology Cyber Security Co., Ltd.); Ying Peng (China Electronics Technology Cyber Security Co., Ltd.); Chenghao Zheng (China Electronics Technology Cyber Security Co., Ltd.); Zongbo Hao (UESTC); Zhang Jian (China Electronics Technology Cyber Security Co., Ltd) <br />
            </p>

<p>
<b>82. <a href='../../wp-content/uploads/papers/0830-paper.pdf'> Contrastive Learning for Lifted Networks</a></b>  <br />
    Christopher Zach (Chalmers University); Virginia Estellers (Microsoft) <br />
            </p>

<p>
<b>83. <a href='../../wp-content/uploads/papers/0907-paper.pdf'> Adaptive Graphical Model Network for 2D Handpose Estimation</a></b>  <br />
    Deying Kong (University of California, Irvine); Yifei Chen (Tencent); Haoyu Ma (Southeast University); Xiangyi Yan (Southern University of Science and Technology); Xiaohui Xie (University of California, Irvine) <br />
            </p>

<p>
<b>84. <a href='../../wp-content/uploads/papers/0934-paper.pdf'> Bag of Negatives for Siamese Architectures</a></b>  <br />
    Bojana Gajic (Computer Vision Center); Ariel Amato (Vintra, Inc.); Ramón Baldrich (Computer Vision Center); Carlo Gatta (Vintra, Inc.) <br />
            </p>

<p>
<b>85. <a href='../../wp-content/uploads/papers/0936-paper.pdf'> SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0936-supplementary.zip'>[Supplementary]</a> <br />
    Shiyang Yan (Queen&#x27;s University Belfast); Yang Hua (Queen&#x27;s University Belfast); Neil Robertson (Queen&#x27;s University Belfast) <br />
            </p>

<p>
<b>86. <a href='../../wp-content/uploads/papers/0944-paper.pdf'> SO(2)-equivariance in Neural networks using tensor nonlinearity</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0944-supplementary.pdf'>[Supplementary]</a> <br />
    Muthuvel Murugan Issakkimuthu (Chennai Mathematical Institute); K V Subrahmanyam (Chennai Mathematical Institute) <br />
            </p>

<p>
<b>87. <a href='../../wp-content/uploads/papers/0968-paper.pdf'> Discriminative Features Matter: Multi-layer Bilinear Pooling for Camera Localization</a></b>  <br />
    Xin Wang (Beihang University); Xiang Wang (Beihang University); Chen Wang (Beihang University); Xiao Bai (Beihang University); Jing Wu (Cardiff University); Edwin Hancock (University of York) <br />
            </p>

<p>
<b>88. <a href='../../wp-content/uploads/papers/1056-paper.pdf'> PrOSe: Product of Orthogonal Spheres Parameterization for Disentangled Representation Learning</a></b>  <br />
    Ankita Shukla (Indraprastha Institute of Information Technology); Shagun Uppal (Indraprastha Institute of Information Technology); Sarthak Bhagat (Indraprastha Institute of Information Technology); Saket Anand (Indraprastha Institute of Information Technology); Pavan Turaga (Arizona State University) <br />
            </p>

<p>
<b>89. <a href='../../wp-content/uploads/papers/1071-paper.pdf'> Dynamic Neural Network Channel Execution for Efficient Training</a></b>  <br />
    Simeon Spasov (University of Cambridge); Pietro Lió (University of Cambridge) <br />
            </p>

<p>
<b>90. <a href='../../wp-content/uploads/papers/1114-paper.pdf'> Class-Distinct and Class-Mutual Image Generation with GANs</a></b>  <br />
    Takuhiro Kaneko (The University of Tokyo); Yoshitaka Ushiku (The University of Tokyo); Tatsuya Harada (The University of Tokyo / RIKEN) <br />
            </p>

<p>
<b>91. <a href='../../wp-content/uploads/papers/1206-paper.pdf'> Classification is a Strong Baseline for Deep Metric Learning</a></b>  <br />
    Hao-Yu Wu (Pinterest, Inc.); Andrew Zhai (Pinterest, Inc.) <br />
            </p>

<p>
<b>92. <a href='../../wp-content/uploads/papers/1240-paper.pdf'> Functionality-Oriented Convolutional Filter Pruning</a></b>  <br />
    Zhuwei Qin (George Mason University); Fuxun Yu (George Mason University); Chenchen Liu (Clarkson University); Xiang Chen (George Mason University) <br />
            </p>

<p>
<b>93. <a href='../../wp-content/uploads/papers/0469-paper.pdf'> Text Recognition using local correlation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0469-supplementary.zip'>[Supplementary]</a> <br />
    Yujia Li (Institute of Information Engineering, Chinese Academy of Sciences); Hongchao Gao (Institute of Information Engineering, Chinese Academy of Sciences); Xi Wang (Institute of Information Engineering, Chinese Academy of Sciences); Jizhong Han (Institute of Information Engineering, Chinese Academy of Sciences); Ruixuan Li (Huazhong University of Science and Technology) <br />
            </p>

<p>
<b>94. <a href='../../wp-content/uploads/papers/0480-paper.pdf'> A Learning-based Text Synthesis Engine for Scene Text Detection</a></b>  <br />
    Xiao Yang (Pennsylvania State University); Dafang He (Pennsylva State University); Dan Kifer (Pennsylva State University); Lee Giles (Pennsylva State University) <br />
            </p>

<p>
<b>95. <a href='../../wp-content/uploads/papers/0647-paper.pdf'> Document Binarization using Recurrent Attention Generative Model</a></b>  <br />
    Shuchun Liu (ele AI Lab); Feiyun Zhang (ele AI Lab); Pan He (University of Florida); Mingxi Chen (Tongji University); Yufei Xie (East China Normal University); Jie Shao (Fudan University) <br />
            </p>

<p>
<b>96. <a href='../../wp-content/uploads/papers/0870-paper.pdf'> End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net</a></b>  <br />
    Tuan Anh Nguyen Dang (Cinnamon); Dat Nguyen Thanh (Cinnamon) <br />
            </p>

<p>
<b>97. <a href='../../wp-content/uploads/papers/0931-paper.pdf'> Unified 2D and 3D Hand Pose Estimation from a Single Visible or X-ray Image</a></b>  <br />
    Akila Pemasiri (Queensland University of Technology); Kien Nguyen Thanh (Queensland University of Technology); Sridha Sridharan (Queensland University of Technology); Clinton  Fookes (Queensland University of Technology) <br />
            </p>

<p>
<b>98. <a href='../../wp-content/uploads/papers/0399-paper.pdf'> Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace</a></b>  <br />
    Dimitrios Kollias (Imperial College London); Stefanos Zafeiriou (Imperial College London) <br />
            </p>

<p>
<b>99. <a href='../../wp-content/uploads/papers/0155-paper.pdf'> Two-stage Image Classification Supervised by a Single Teacher Single Student Model</a></b>  <br />
    Jianhang Zhou (University of Macau); Shaoning Zeng (University of Macau, Huizhou University); Bob Zhang (Univerisity of Macau) <br />
            </p>

<p>
<b>100. <a href='../../wp-content/uploads/papers/0254-paper.pdf'> MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American Sign Language</a></b>  <br />
    HAMID VAEZI JOZE (Microsoft); Oscar Koller (Microsoft) <br />
            </p>

<p>
<b>101. <a href='../../wp-content/uploads/papers/0257-paper.pdf'> Trajectory Space Factorization for Deep Video-Based 3D Human Pose Estimation</a></b>  <br />
    Jiahao Lin (National University of Singapore); Gim Hee Lee (National University of Singapore) <br />
            </p>

<p>
<b>102. <a href='../../wp-content/uploads/papers/0268-paper.pdf'> BIRD: Learning Binary and Illumination Robust Descriptor for Face Recognition</a></b>  <br />
    Zhuo Su (University of Oulu); Matti Pietikäinen (University of Oulu); Li Liu (University of Oulu) <br />
            </p>

<p>
<b>103. <a href='../../wp-content/uploads/papers/0281-paper.pdf'> Construct Dynamic Graphs for Hand Gesture Recognition via Spatial-Temporal Attention</a></b>  <br />
    Yuxiao Chen (Rutgers University); Long Zhao (Rutgers University); Xi Peng (University of Delaware); Jianbo Yuan (University of Rochester); Dimitris Metaxas (Rutgers University) <br />
            </p>

<p>
<b>104. <a href='../../wp-content/uploads/papers/0321-paper.pdf'> Annealed Label Transfer for Face Expression Recognition</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0321-supplementary.zip'>[Supplementary]</a> <br />
    Corneliu Florea (University Politehnica of Bucharest); Laura Florea (University Politehnica of Bucharest); Mihai Badea (Image Processing and Analysis Laboratory, University Politehnica of Bucharest); Constantin Vertan (University Politehnica of Bucarest); Andrei Racoviteanu (University Politehnica of Bucharest) <br />
            </p>

<p>
<b>105. <a href='../../wp-content/uploads/papers/0326-paper.pdf'> FlickerNet: Adaptive 3D Gesture Recognition from Sparse Point Clouds</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0326-supplementary.zip'>[Supplementary]</a> <br />
    Yuecong Min (Institute of Computing Technology, Chinese Academy of Sciences); Xiujuan Chai (Agricultural Information Institute); Lei Zhao (HUAWEI Technologies Co., Ltd.); Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences) <br />
            </p>

<p>
<b>106. <a href='../../wp-content/uploads/papers/0352-paper.pdf'> Pose-Aware Face Alignment based on CNN and 3DMM</a></b>  <br />
    Songjiang Li (Peking University); Honggai Li (Peking University); Jinshi Cui (Peking University); Hongbin Zha (Peking University) <br />
            </p>

<p>
<b>107. <a href='../../wp-content/uploads/papers/0403-paper.pdf'> Unmasking the Devil in the Details:What Works for Deep Facial Action Coding?</a></b>  <br />
    Koichiro Niinuma (Fujitsu Laboratories of America, Inc.); Laszlo Jeni (Carnegie Mellon University); Jeffrey Cohn (University of Pittsburgh); Itir Onal Ertugrul (Carnegie Mellon University) <br />
            </p>

<p>
<b>108. <a href='../../wp-content/uploads/papers/0498-paper.pdf'> Large Margin Loss for Learning Facial Movements from Pseudo-Emotions</a></b>  <br />
    Andrei Racoviteanu (University Politehnica of Bucharest); Mihai Badea (Image Processing and Analysis Laboratory, University Politehnica of Bucharest); Corneliu Florea (University Politehnica of Bucharest); Laura Florea (University Politehnica of Bucharest); Constantin Vertan (University Politehnica of Bucarest) <br />
            </p>

<p>
<b>109. <a href='../../wp-content/uploads/papers/0576-paper.pdf'> Body Part Alignment and Temporal Attention Pooling for Video-Based Person Re-Identification</a></b>  <br />
    Michael Jones (Mitsubishi Electric Research Laboratories); Sai Saketh Rambhatla (University of Maryland) <br />
            </p>

<p>
<b>110. <a href='../../wp-content/uploads/papers/0729-paper.pdf'> Automatic 4D Facial Expression Recognition via Collaborative Cross-domain Dynamic Image Network</a></b>  <br />
    Muzammil Behzad (University of Oulu); Nhat Vo (University of Oulu); Xiaobai Li (University of Oulu); Guoying Zhao (University of Oulu) <br />
            </p>

<p>
<b>111. <a href='../../wp-content/uploads/papers/0772-paper.pdf'> Enhanced Normalized Mean Error loss for Robust Facial Landmark detection</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0772-supplementary.zip'>[Supplementary]</a> <br />
    Shenqi Lai (MeituanDianping Group); Zhenhua Chai (MeituanDianping Group); Huanhuan Meng (MeituanDianping Group); Shengxi Li (MeituanDianping Group); Mengzhao Yang (MeituanDianping Group); Xiaoming Wei (MeituanDianping Group) <br />
            </p>

<p>
<b>112. <a href='../../wp-content/uploads/papers/0918-paper.pdf'> SRN: Stacked Regression Network for Real-time 3D Hand Pose Estimation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0918-supplementary.pdf'>[Supplementary]</a> <br />
    Pengfei Ren (Beijing University of Posts and Telecommunications); Haifeng Sun (Beijing University of Posts and Telecommunications); Jingyu Wang (Beijing University of Posts and Telecommunications); Qi Qi (Beijing University of Posts and Telecommunications); Weiting Huang (Beijing University of Posts and Telecommunications) <br />
            </p>

<p>
<b>113. <a href='../../wp-content/uploads/papers/0973-paper.pdf'> Face Anti-Spoofing via Sample Learning Based Recurrent Neural Network (RNN)</a></b>  <br />
    Usman Muhammad (University of Oulu); Abdenour Hadid (University of Oulu); Wheidima Melo (University of Oulu); Tuomas Kristian Holmberg (University of Oulu) <br />
            </p>

<p>
<b>114. <a href='../../wp-content/uploads/papers/0988-paper.pdf'> PAttNet: Patch-attentive deep network for action unit detection</a></b>  <br />
    Itir Onal Ertugrul (Carnegie Mellon University); Laszlo Jeni (Carnegie Mellon University); Jeffrey Cohn (University of Pittsburgh) <br />
            </p>

<p>
<b>115. <a href='../../wp-content/uploads/papers/0219-paper.pdf'> End-to-End 3D Hand Pose Estimation from Stereo Cameras</a></b>  <br />
    Yuncheng Li (Snap Inc.); Zehao Xue (Snap Inc.); Yingying Wang (Snap Inc.); Liuhao Ge (Nanyang Technological University); Zhou Ren (Wormpex AI Research); Jonathan Rodriguez (Snap Inc.) <br />
            </p>

<p>
<b>116. <a href='../../wp-content/uploads/papers/0408-paper.pdf'> TAGAN: Tonality Aligned Generative Adversarial Networks for Realistic Hand Pose Synthesis</a></b>  <br />
    Liangjian Chen (University of California, Irvine); Shih-Yao Lin (Tencent Medical AI Lab); Yusheng Xie (Tencent Medical AI Lab); Hui Tang (Tecent Medical AI Lab); Yufan Xue (workday); Yen-Yu Lin (Academia Sinica); Xiaohui Xie (University of California, Irvine); Wei Fan (Tencent) <br />
            </p>

<p>
<b>117. <a href='../../wp-content/uploads/papers/0702-paper.pdf'> Frustratingly Easy Person Re-Identification: Generalizing Person Re-ID in Practice</a></b>  <br />
    Jieru Jia (Beijing Jiaotong University); Qiuqi Ruan (Beijing Jiaotong University); Timothy Hospedales (Edinburgh University) <br />
            </p>

<p>
<b>118. <a href='../../wp-content/uploads/papers/0539-paper.pdf'> Delving Deep into Least Square Regression Model for Subspace Clustering </a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0539-supplementary.zip'>[Supplementary]</a> <br />
    Masataka Yamaguchi (NTT Corporation); Go Irie (NTT Communication Science Laboratories); Takahito Kawanishi (NTT Corporation); Kunio Kashino (NTT Corporation) <br />
            </p>

<p>
<b>119. <a href='../../wp-content/uploads/papers/0555-paper.pdf'> Variational Saccading: Efficient Inference for Large Resolution Images</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0555-supplementary.zip'>[Supplementary]</a> <br />
    Jason Ramapuram (University of Geneva); Russ Webb (Apple); Maurits Diephuis (University of Geneva); Alexandros Kalousis (AU Geneva); Frantzeska Lavda (University of Geneva) <br />
            </p>

<p>
<b>120. <a href='../../wp-content/uploads/papers/0852-paper.pdf'> An Acceleration Scheme for Mini-batch, Streaming PCA</a></b>  <br />
    Salaheddin Alakkari (Trinity College Dublin); John Dingliana (Trinity College Dublin) <br />
            </p>

<p>
<b>121. <a href='../../wp-content/uploads/papers/1067-paper.pdf'> A Generic Active Learning Framework for Class Imbalance Applications</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1067-supplementary.pdf'>[Supplementary]</a> <br />
    Aditya Bhattacharya (Florida State University); Ji Liu (University of Rochester); Shayok Chakraborty (Florida State University) <br />
            </p>

<p>
<b>122. <a href='../../wp-content/uploads/papers/0807-paper.pdf'> Transductive Learning Via Improved Geodesic Sampling</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0807-supplementary.pdf'>[Supplementary]</a> <br />
    Youshan Zhang (Lehigh University); Brian Davison (Lehigh University); Sihong Xie (Lehigh University) <br />
            </p>

<p>
<b>123. <a href='../../wp-content/uploads/papers/0310-paper.pdf'> A General Transductive Regularizer for Zero-Shot Learning</a></b>  <br />
    Huaqi Mao (Nanjing University of Science and Technology); Haofeng Zhang (Nanjing University of Science and Technology); Shidong Wang (University of East Anglia); Yang Long (Newcastle University); Longzhi Yang (Northumbria University) <br />
            </p>

<p>
<b>124. <a href='../../wp-content/uploads/papers/0333-paper.pdf'> A Less Biased Evaluation of Out-of-distribution Sample Detectors</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0333-supplementary.zip'>[Supplementary]</a> <br />
    Alireza Shafaei (The University of British Columbia); Mark Schmidt (University of British Columbia); Jim Little (University of British Columbia) <br />
            </p>

<p>
<b>125. <a href='../../wp-content/uploads/papers/0416-paper.pdf'> Relation-aware Multiple Attention Siamese Networks for Robust Visual Tracking</a></b>  <br />
    Fangyi Zhang (Chinese Academy of Sciences); Bingpeng Ma (Chinese Academy of Sciences); Hong Chang (Chinese Academy of Sciences); Shiguang Shan (Chinese Academy of Sciences); Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences) <br />
            </p>

<p>
<b>126. <a href='../../wp-content/uploads/papers/0589-paper.pdf'> Spatial Transformer Spectral Kernels for Deformable Image Registration</a></b>  <br />
    Ebrahim Al Safadi (Oregon Health and Science University); Xubo Song (Oregon Health and Science University) <br />
            </p>

<p>
<b>127. <a href='../../wp-content/uploads/papers/1003-paper.pdf'> Tracking the Known and the Unknown by Leveraging Semantic Information</a></b>  <br />
    Ardhendu Shekhar Tripathi (ETH Zurich); Martin Danelljan (ETH Zurich); Luc Van Gool (ETH Zurich); Radu Timofte (ETH Zurich) <br />
            </p>

<p>
<b>128. <a href='../../wp-content/uploads/papers/1065-paper.pdf'> Tracking Holistic Object Representations</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1065-supplementary.pdf'>[Supplementary]</a> <br />
    Axel Sauer (Technical University of Munich); Elie Aljalbout (Technical University of Munich); Sami Haddadin (Technical University of Munich) <br />
            </p>

<p>
<b>129. <a href='../../wp-content/uploads/papers/0265-paper.pdf'> Video Upright Adjustment and Stabilization</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0265-supplementary.zip'>[Supplementary]</a> <br />
    Jucheol Won (DGIST); Sunghyun Cho (POSTECH) <br />
            </p>

<p>
<b>130. <a href='../../wp-content/uploads/papers/0453-paper.pdf'> Video Stitching for Linear Camera Arrays</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0453-supplementary.pdf'>[Supplementary]</a> <br />
    Wei-Sheng Lai (University of California, Merced); Orazio Gallo (NVIDIA Research); Jinwei Gu (NVIDIA); Deqing Sun (Google); Ming-Hsuan Yang (University of California at Merced); Jan Kautz (NVIDIA) <br />
            </p>

<p>
<b>131. <a href='../../wp-content/uploads/papers/0562-paper.pdf'> Learning Target-aware Attention for Robust Tracking with Conditional Adversarial Network</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0562-supplementary.pdf'>[Supplementary]</a> <br />
    Xiao Wang (Anhui University); Rui Yang (Anhui university); Tao Sun (Anhui university); Bin Luo (Anhui University) <br />
            </p>

<p>
<b>132. <a href='../../wp-content/uploads/papers/0564-paper.pdf'> Bilinear Siamese Networks with Background Suppression for Visual Object Tracking</a></b>  <br />
    Hankyeol Lee (Korea Advanced Institute of Science and Technology); Seokeon Choi (Korea Advanced Institute of Science and Technology); Youngeun Kim (Korea Advanced Institute of Science and Technology); Changick Kim (Korea Advanced Institute of Science and Technology) <br />
            </p>

<p>
<b>133. <a href='../../wp-content/uploads/papers/0728-paper.pdf'> Learning to Focus and Track Extreme Climate Events</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0728-supplementary.pdf'>[Supplementary]</a> <br />
    Sookyung Kim (Lawrence Livermore National Laboratory); Sunghyun Park (Korea University); Sunghyo Chung (Korea University); Joonseok Lee (Google Research); Yunsung Lee (Korea University); Hyojin Kim (LLNL); Prabhat (Lawrence Berkeley National Laboratory); Jaegul Choo (Korea University) <br />
            </p>

<p>
<b>134. <a href='../../wp-content/uploads/papers/0949-paper.pdf'> Features for Ground Texture Based Localization &#8211; A Survey</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0949-supplementary.pdf'>[Supplementary]</a> <br />
    Jan Fabian Schmid (Robert Bosch GmbH); Stephan F. Simon (Robert Bosch GmbH); Rudolf Mester (NTNU Trondheim) <br />
            </p>

<p>
<b>135. <a href='../../wp-content/uploads/papers/0599-paper.pdf'> Self-supervised Video Representation Learning for Correspondence Flow</a></b>  <br />
    Zihang Lai (University of Oxford); Weidi Xie (University of Oxford) <br />
            </p>

<p>
<b>136. <a href='../../wp-content/uploads/papers/0997-paper.pdf'> PMnet: Learning of Disentangled Pose and Movement for Unsupervised Motion Retargeting</a></b>  <br />
    Jongin Lim (Seoul National University); Hyung Jin Chang (University of Birmingham); Jin Young Choi (Seoul National University) <br />
            </p>

</div>
</div>
<div>
<p>
<b>16:15 &#8212; 18:15 &nbsp;&nbsp;Oral Presentations: Deep Learning for Vision (Session 2)</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p>Chair: Bernard Tiddeman <br />Sponsored by Snap Inc.</p>
</div>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_4'>
<p>
<b>137. <a href='../../wp-content/uploads/papers/0203-paper.pdf'> Do Saliency Models Detect Odd-One-Out Targets? New Datasets and Evaluations</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0203-supplementary.zip'>[Supplementary]</a> <br />
    Iuliia Kotseruba (York University); Calden Wloka (York University); Amir Rasouli (York University); John Tsotsos (York University) <br />
            </p>

<p>
<b>138. <a href='../../wp-content/uploads/papers/0550-paper.pdf'> PCAS: Pruning Channels with Attention Statistics for Deep Network Compression</a></b>  <br />
    Kohei Yamamoto (Oki Electric Industry Co., Ltd.); Kurato Maeno (Oki Electric Industry Co., Ltd.) <br />
            </p>

<p>
<b>139. <a href='../../wp-content/uploads/papers/0636-paper.pdf'> Large Margin In Softmax Cross-Entropy Loss</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0636-supplementary.zip'>[Supplementary]</a> <br />
    Takumi Kobayashi (National Institute of Advanced Industrial Science and Technology) <br />
            </p>

<p>
<b>140. <a href='../../wp-content/uploads/papers/0717-paper.pdf'> Differentiable Unrolled Alternating Direction Method of Multipliers for OneNet</a></b>  <br />
    Zoltán Milacski (Eötvös Loránd University); Barnabas Poczos (Carnegie Mellon University); Andras Lorincz (Eötvös Loránd University) <br />
            </p>

<p>
<b>141. <a href='../../wp-content/uploads/papers/0821-paper.pdf'> Graph-based Knowledge Distillation by Multi-head Attention Network</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0821-supplementary.pdf'>[Supplementary]</a> <br />
    Seunghyun Lee (Inha University); Byung Cheol Song (Inha University) <br />
            </p>

<p>
<b>142. <a href='../../wp-content/uploads/papers/0865-paper.pdf'> Convolutional CRFs for Semantic Segmentation</a></b>  <br />
    Marvin Teichmann (University of Cambridge); Roberto Cipolla (University of Cambridge) <br />
            </p>

<p>
<b>143. <a href='../../wp-content/uploads/papers/0885-paper.pdf'> Group Based Deep Shared Feature Learning for Fine-grained Image Classification</a></b>  <br />
    Xuelu Li (The Pennsylvania State University); Vishal Monga (Pennsylvania State University) <br />
            </p>

<p>
<b>144. <a href='../../wp-content/uploads/papers/1007-paper.pdf'> Addressing Data Bias Problems for Chest X-ray Image Report Generation</a></b>  <br />
    Philipp Harzig (University of Augsburg); Yan-Ying Chen (FX Pal); Francine Chen (FX Palo Alto Laboratory); Rainer Lienhart (Universitat Augsburg) <br />
            </p>

</div>
</div>
<div>
<p>
<b>19:00 &#8212; late &nbsp;&nbsp;Dinner</b>
<i>SU, Y Plas</i>
</p>
</div>
<hr />
<h2>Wednesday 11<sup>th</sup> September</h2>
<div>
<p>
<b>08:00 &#8212; 09:00 &nbsp;&nbsp;Registration</b>
</p>
</div>
<div>
<p>
<b>09:00 &#8212; 10:00 &nbsp;&nbsp;Keynote</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p><b>Automatic Understanding of the Visual World</b><br /> Prof. Cordelia Schmid (Inria) <br />Sponsored by Scape</p>
</div>
</p>
</div>
<div>
<p>
<b>10:00 &#8212; 11:00 &nbsp;&nbsp;Spotlights (Session 2)</b>
<i>Sir Martin Evans Building</i>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_5'>
<p>
<b>145. <a href='../../wp-content/uploads/papers/0078-paper.pdf'> Object Affordances Graph Network for Action Recognition</a></b>  <br />
    Haoliang Tan (Xi&#x27;an Jiaotong University); Le Wang (Xi&#x27;an Jiaotong University); Qilin Zhang (HERE Technologies); Zhanning Gao (Alibaba Group); Nanning Zheng (Xi&#x27;an Jiaotong University); Gang Hua (Wormpex AI Research) <br />
            </p>

<p>
<b>146. <a href='../../wp-content/uploads/papers/0124-paper.pdf'> Image Captioning with Unseen Objects</a></b>  <br />
    Berkan Demirel (HAVELSAN Inc. &amp; METU); Ramazan Gokberk Cinbis (METU); Nazli Ikizler-Cinbis (Hacettepe University) <br />
            </p>

<p>
<b>147. <a href='../../wp-content/uploads/papers/0168-paper.pdf'> Residual Multiscale Based Single Image Deraining</a></b>  <br />
    Yupei Zheng (Beijing Jiaotong University); Xin Yu (Australian National University); Miaomiao Liu (Australian National University); Shunli Zhang (Beijing Jiaotong University) <br />
            </p>

<p>
<b>148. <a href='../../wp-content/uploads/papers/0347-paper.pdf'> Open-set Recognition of Unseen Macromolecules in Cellular Electron Cryo-Tomograms by Soft Large Margin Centralized Cosine Loss</a></b>  <br />
    Xuefeng Du (Xi&#x27;an Jiaotong University); Xiangrui Zeng (Carnegie Mellon University); Bo Zhou (Yale University); Alex Singh (Carnegie Mellon University); Min Xu (Carnegie Mellon University) <br />
            </p>

<p>
<b>149. <a href='../../wp-content/uploads/papers/0355-paper.pdf'> Learnable Gated Temporal Shift Module for Free-form Video Inpainting</a></b>  <br />
    Ya-Liang Chang (National Taiwan University); Zhe Yu Liu (National Taiwan University); Kuan-Ying Lee (National Taiwan University); Winston Hsu (National Taiwan University) <br />
            </p>

<p>
<b>150. <a href='../../wp-content/uploads/papers/0413-paper.pdf'> MS-GAN: Text to Image Synthesis with Attention-Modulated Generators and Similarity-aware Discriminators</a></b>  <br />
    Fengling Mao (Chinese Academy of Sciences ); Bingpeng Ma (Chinese Academy of Sciences); Hong Chang (Chinese Academy of Sciences); Shiguang Shan (Chinese Academy of Sciences); Xilin Chen (Chinese Academy of Sciences) <br />
            </p>

<p>
<b>151. <a href='../../wp-content/uploads/papers/0417-paper.pdf'> Unsupervised and Explainable Assessment of Video Similarity</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0417-supplementary.zip'>[Supplementary]</a> <br />
    Konstantinos Papoutsakis (University of Crete &amp; ICS-FORTH, Greece); Antonis Argyros (CSD-UOC and ICS-FORTH) <br />
            </p>

<p>
<b>152. <a href='../../wp-content/uploads/papers/0474-paper.pdf'> AutoCorrect: Deep Inductive Alignment of Noisy Geometric Annotations</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0474-supplementary.pdf'>[Supplementary]</a> <br />
    Honglie Chen (University of Oxford); Weidi Xie (University of Oxford); Andrea Vedaldi (University of Oxford); Andrew Zisserman (University of Oxford) <br />
            </p>

<p>
<b>153. <a href='../../wp-content/uploads/papers/0649-paper.pdf'> Adaptive Compression-based Lifelong Learning</a></b>  <br />
    Shivangi Srivastava (Wageningen University and Research); Maxim Berman (KU Leuven); Matthew Blaschko (KU Leuven); Devis Tuia (Wageningen University and Research) <br />
            </p>

<p>
<b>154. <a href='../../wp-content/uploads/papers/0650-paper.pdf'> TARN: Temporal Attentive Relation Network for Few-Shot and Zero-Shot Action Recognition</a></b>  <br />
    Bishay Mina (Queen Mary University London); Georgios Zoumpourlis (Queen Mary University of London); Ioannis Patras (Queen Mary University of London) <br />
            </p>

<p>
<b>155. <a href='../../wp-content/uploads/papers/0723-paper.pdf'> Adaptive Lighting for Data-Driven Non-Line-of-Sight 3D Localization and Object Identification</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0723-supplementary.zip'>[Supplementary]</a> <br />
    Sreenithy Chandran (Arizona State University); Suren Jayasuriya (Arizona State University) <br />
            </p>

<p>
<b>156. <a href='../../wp-content/uploads/papers/0726-paper.pdf'> Hybrid Deep Network for Anomaly Detection</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0726-supplementary.zip'>[Supplementary]</a> <br />
    Trong Nguyen Nguyen (University of Montreal); Jean Meunier (University of Montreal) <br />
            </p>

<p>
<b>157. <a href='../../wp-content/uploads/papers/0788-paper.pdf'> Fast and Multilevel Semantic-Preserving Discrete Hashing</a></b>  <br />
    Wanqian Zhang (Chinese Academy of Sciences); Dayan Wu (Chinese Academy of Sciences); Jing Liu (Chinese Academy of Sciences); Bo Li (Chinese Academy of Sciences); Xiaoyan Gu (Chinese Academy of Sciences); Weiping Wang (Chinese Academy of Sciences); Dan Meng (Chinese Academy of Sciences) <br />
            </p>

<p>
<b>158. <a href='../../wp-content/uploads/papers/0839-paper.pdf'> Mining Discriminative Food Regions for Accurate Food Recognition</a></b>  <br />
    Jianing Qiu (Imperial College London); Po Wen Lo (Imperial College London); Yingnan Sun (Imperial College London); Siyao Wang (Imperial College London); Benny Lo (Imperial College London) <br />
            </p>

<p>
<b>159. <a href='../../wp-content/uploads/papers/0996-paper.pdf'> Attentional demand estimation with attentive driving models</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0996-supplementary.mp4'>[Supplementary]</a> <br />
    Petar Palasek (MindVisionLabs); Nilli Lavie (University College London, MindVisionLabs); Luke Palmer (MindVisionLabs) <br />
            </p>

</div>
</div>
<div>
<p>
<b>11:00 &#8212; 11:45 &nbsp;&nbsp;Tea Break</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>11:45 &#8212; 13:15 &nbsp;&nbsp;Oral Presentations: 3D Computer Vision</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p>Chair: Majid Mirmehdi <br />Sponsored by Roke</p>
</div>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_6'>
<p>
<b>161. <a href='../../wp-content/uploads/papers/0219-paper.pdf'> End-to-End 3D Hand Pose Estimation from Stereo Cameras</a></b>  <br />
    Yuncheng Li (Snap Inc.); Zehao Xue (Snap Inc.); Yingying Wang (Snap Inc.); Liuhao Ge (Nanyang Technological University); Zhou Ren (Wormpex AI Research); Jonathan Rodriguez (Snap Inc.) <br />
            </p>

<p>
<b>162. <a href='../../wp-content/uploads/papers/0331-paper.pdf'> Triangulation: Why Optimize?</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0331-supplementary.zip'>[Supplementary]</a> <br />
    Seong Hun Lee (University of Zaragoza); Javier Civera (Universidad de Zaragoza) <br />
            </p>

<p>
<b>163. <a href='../../wp-content/uploads/papers/0392-paper.pdf'> Single-view Object Shape Reconstruction Using Deep Shape Prior and Silhouette</a></b>  <br />
    Kejie Li (University of Adelaide); Ravi Garg (University of Adelaide); Ming Cai (The University of Adelaide); Ian Reid (University of Adelaide) <br />
            </p>

<p>
<b>164. <a href='../../wp-content/uploads/papers/0452-paper.pdf'> Learning Embedding of 3D models with Quadric Loss</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0452-supplementary.pdf'>[Supplementary]</a> <br />
    Nitin Agarwal (Department of Computer Science, UC-Irvine); Sungeui Yoon (Korea Advanced Institute of Science and Technology); M Gopi (University of California, Irvine) <br />
            </p>

<p>
<b>165. <a href='../../wp-content/uploads/papers/0568-paper.pdf'> Probabilistic Reconstruction Networks for 3D Shape Inference from a Single Image</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0568-supplementary.zip'>[Supplementary]</a> <br />
    Roman Klokov (Inria); Jakob Verbeek (Inria); Edmond Boyer (Inria) <br />
            </p>

<p>
<b>166. <a href='../../wp-content/uploads/papers/0816-paper.pdf'> Optimal Multi-view Correction of Local Affine Frames</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0816-supplementary.pdf'>[Supplementary]</a> <br />
    Iván Eichhardt (MTA SZTAKI); Dániel Baráth (MTA SZTAKI, CMP Prague) <br />
            </p>

</div>
</div>
<div>
<p>
<b>13:15 &#8212; 14:00 &nbsp;&nbsp;Lunch</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>14:00 &#8212; 16:15 &nbsp;&nbsp;Posters (Session 2)</b>
<i>SU, Great Hall</i>
<br /><a href='#/' onclick="toggleList('#session_7')">[Toggle Poster List]</a>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_7'>
<p>
<b>167. <a href='../../wp-content/uploads/papers/0585-paper.pdf'> Forecasting Future Action Sequences with Neural Memory Networks</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0585-supplementary.zip'>[Supplementary]</a> <br />
    Harshala Gammulle (Queensland University of Technology); Simon Denman (Queensland University of Technology); Sridha Sridharan (Queensland University of Technology); Clinton Fookes (Queensland University of Technology) <br />
            </p>

<p>
<b>168. <a href='../../wp-content/uploads/papers/0078-paper.pdf'> Object Affordances Graph Network for Action Recognition</a></b>  <br />
    Haoliang Tan (Xi&#x27;an Jiaotong University); Le Wang (Xi&#x27;an Jiaotong University); Qilin Zhang (HERE Technologies); Zhanning Gao (Alibaba Group); Nanning Zheng (Xi&#x27;an Jiaotong University); Gang Hua (Wormpex AI Research) <br />
            </p>

<p>
<b>169. <a href='../../wp-content/uploads/papers/0122-paper.pdf'> Zero-Shot Sign Language Recognition: Can Textual Data Uncover Sign Languages?</a></b>  <br />
    Yunus Can Bilge (Hacettepe University); Nazli Ikizler-Cinbis (Hacettepe University); Ramazan Gokberk Cinbis (METU) <br />
            </p>

<p>
<b>170. <a href='../../wp-content/uploads/papers/0162-paper.pdf'> An Efficient 3D CNN for Action/Object Segmentation in Video</a></b>  <br />
    Rui Hou (UCF); Chen Chen (University of North Carolina at Charlotte); Mubarak Shah (University of Central Florida); Rahul Sukthankar (Google) <br />
            </p>

<p>
<b>171. <a href='../../wp-content/uploads/papers/0283-paper.pdf'> Pedestrian Action Anticipation using Contextual Feature Fusion in Stacked RNNs</a></b>  <br />
    Amir Rasouli (York University); Iuliia Kotseruba (York University); John Tsotsos (York University) <br />
            </p>

<p>
<b>172. <a href='../../wp-content/uploads/papers/0299-paper.pdf'> Focused Attention for Action Recognition</a></b>  <br />
    Vladyslav Sydorov (Inria); Karteek Alahari (Inria); Cordelia Schmid (Inria) <br />
            </p>

<p>
<b>173. <a href='../../wp-content/uploads/papers/0417-paper.pdf'> Unsupervised and Explainable Assessment of Video Similarity</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0417-supplementary.zip'>[Supplementary]</a> <br />
    Konstantinos Papoutsakis (University of Crete &amp; ICS-FORTH, Greece); Antonis Argyros (CSD-UOC and ICS-FORTH) <br />
            </p>

<p>
<b>174. <a href='../../wp-content/uploads/papers/0524-paper.pdf'> Dynamic Graph Modules for Modeling Object-Object Interactions in Activity Recognition</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0524-supplementary.pdf'>[Supplementary]</a> <br />
    Hao Huang (University of Rochester); Luowei Zhou (University of Michigan); Wei Zhang (University of Rochester); Jason Corso (University of Michigan); Chenliang Xu (University of Rochester) <br />
            </p>

<p>
<b>175. <a href='../../wp-content/uploads/papers/0552-paper.pdf'> Weakly-Supervised 3D Pose Estimation from a Single Image using Multi-View Consistency</a></b>  <br />
    Guillaume Rochette (University of Surrey); Chris Russell (University of Surrey); Richard Bowden (University of Surrey) <br />
            </p>

<p>
<b>176. <a href='../../wp-content/uploads/papers/0615-paper.pdf'> Learning Visual Actions Using Multiple Verb-Only Labels</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0615-supplementary.mp4'>[Supplementary]</a> <br />
    Michael Wray (University of Bristol); Dima Damen (University of Bristol) <br />
            </p>

<p>
<b>177. <a href='../../wp-content/uploads/papers/0650-paper.pdf'> TARN: Temporal Attentive Relation Network for Few-Shot and Zero-Shot Action Recognition</a></b>  <br />
    Bishay Mina (Queen Mary University London); Georgios Zoumpourlis (Queen Mary University of London); Ioannis Patras (Queen Mary University of London) <br />
            </p>

<p>
<b>178. <a href='../../wp-content/uploads/papers/0880-paper.pdf'> A Spatiotemporal Pre-processing Network for Activity Recognition under Rain</a></b>  <br />
    Minah Lee (Georgia Institute of Technology); Burhan Mudassar (Georgia Institute of Technology); Taesik Na (Georgia Institute of Technology); Saibal Mukhopadhyay (Georgia Institute of Technology) <br />
            </p>

<p>
<b>179. <a href='../../wp-content/uploads/papers/0203-paper.pdf'> Do Saliency Models Detect Odd-One-Out Targets? New Datasets and Evaluations</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0203-supplementary.zip'>[Supplementary]</a> <br />
    Iuliia Kotseruba (York University); Calden Wloka (York University); Amir Rasouli (York University); John Tsotsos (York University) <br />
            </p>

<p>
<b>180. <a href='../../wp-content/uploads/papers/0996-paper.pdf'> Attentional demand estimation with attentive driving models</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0996-supplementary.mp4'>[Supplementary]</a> <br />
    Petar Palasek (MindVisionLabs); Nilli Lavie (University College London, MindVisionLabs); Luke Palmer (MindVisionLabs) <br />
            </p>

<p>
<b>181. <a href='../../wp-content/uploads/papers/1140-paper.pdf'> Edge Detection for Event Cameras using Intra-pixel-area Events</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1140-supplementary.mp4'>[Supplementary]</a> <br />
    Sangil Lee (Seoul National University); Haram Kim (Seoul National University); Hyoun Jin Kim (Seoul National University) <br />
            </p>

<p>
<b>182. <a href='../../wp-content/uploads/papers/0952-paper.pdf'> Simple vs complex temporal recurrences for video saliency prediction</a></b>  <br />
    Panagiotis Linardos (Insight Center for Data Analytics); Eva Mohedano (Insight Center for Data Analytics); Juan Jose Nieto (Insight Center for Data Analytics); Noel O&#x27;Connor (Dublin City University (DCU)); Xavier Giro-i-Nieto (Universitat Politecnica de Catalunya); Kevin McGuinness (Insight Centre for Data Analytics) <br />
            </p>

<p>
<b>183. <a href='../../wp-content/uploads/papers/0105-paper.pdf'> Sensor-Independent Illumination Estimation for DNN Models</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0105-supplementary.zip'>[Supplementary]</a> <br />
    Mahmoud Afifi (York University); Michael Brown (York University) <br />
            </p>

<p>
<b>184. <a href='../../wp-content/uploads/papers/0216-paper.pdf'> Convolutional Mean: A Simple Convolutional Neural Network for Illuminant Estimation</a></b>  <br />
    Han Gong (University of East Anglia) <br />
            </p>

<p>
<b>185. <a href='../../wp-content/uploads/papers/0723-paper.pdf'> Adaptive Lighting for Data-Driven Non-Line-of-Sight 3D Localization and Object Identification</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0723-supplementary.zip'>[Supplementary]</a> <br />
    Sreenithy Chandran (Arizona State University); Suren Jayasuriya (Arizona State University) <br />
            </p>

<p>
<b>186. <a href='../../wp-content/uploads/papers/0721-paper.pdf'> Content and Colour Distillation for Learning Image Translations with the Spatial Profile Loss</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0721-supplementary.pdf'>[Supplementary]</a> <br />
    Saquib Sarfraz (Karlsruhe Institute of Technology); Constantin Seibold (Karlsruhe Institute of Technology); Haroon Khalid (Karlsruhe Institute of Technology); Rainer Stiefelhagen (Karlsruhe Institute of Technology) <br />
            </p>

<p>
<b>187. <a href='../../wp-content/uploads/papers/0039-paper.pdf'> Quantitative Analysis of Similarity Measures of Distributions</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0039-supplementary.pdf'>[Supplementary]</a> <br />
    Eric Bazán (PSL Research University &#8211; MINES ParisTech); Petr Dokládal (	PSL Research University &#8211; MINES ParisTech); Eva Dokládalová (Université Paris-Est, LIGM, UMR 8049, ESIEE Paris) <br />
            </p>

<p>
<b>188. <a href='../../wp-content/uploads/papers/0103-paper.pdf'> Gated Multiple Feedback Network for Image Super-Resolution</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0103-supplementary.pdf'>[Supplementary]</a> <br />
    Qilei Li (Sichuan University); Zhen Li (Sichuan University); Lu Lu (Sichuan University); Gwanggil Jeon (Incheon National University); Kai Liu (Sichuan University); Xiaomin Yang (Sichuan University) <br />
            </p>

<p>
<b>189. <a href='../../wp-content/uploads/papers/0288-paper.pdf'> Wide Activation for Efficient Image and Video Super-Resolution</a></b>  <br />
    Jiahui Yu (University of Illinois at Urbana-Champaign); Yuchen Fan (University of Illinois at Urbana-Champaign); Thomas Huang (University of Illinois at Urbana-Champaign) <br />
            </p>

<p>
<b>190. <a href='../../wp-content/uploads/papers/0553-paper.pdf'> Higher order Dictionary Learning for Compressed Sensing based Dynamic MRI reconstruction</a></b>  <br />
    Minha Mubarak (Indian Institute of Space Science and Technology); Thomas James Thomas (Indian Institute of Space Science and Technology); Sheeba Rani J (Indian Institute of Space Science and Technology); Deepak Mishra (Indian Institute of Space Science and Technology) <br />
            </p>

<p>
<b>191. <a href='../../wp-content/uploads/papers/0754-paper.pdf'> Robust Joint Image Reconstruction from Color and Monochrome Cameras</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0754-supplementary.zip'>[Supplementary]</a> <br />
    Muxingzi Li (Inria); Peihan Tu (University of Tokyo); Wolfgang Heidrich (KAUST) <br />
            </p>

<p>
<b>192. <a href='../../wp-content/uploads/papers/0820-paper.pdf'> Progressive Face Super-Resolution via Attention to Facial Landmark</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0820-supplementary.zip'>[Supplementary]</a> <br />
    Deokyun Kim (Korea Advanced Institute of Science and Technology); Minseon Kim (Korea Advanced Institute of Science and Technology); Gihyun Kwon (Korea Advanced Institute of Science and Technology); Daeshik Kim (Korea Advanced Institute of Science and Technology) <br />
            </p>

<p>
<b>193. <a href='../../wp-content/uploads/papers/0831-paper.pdf'> An Unsupervised Subspace Ranking Method for Continuous Emotions in Face Images</a></b>  <br />
    Pooyan Balouchian (University of Central Florida); Marjaneh Safaei (University of Central Florida); Xiaochun Cao (Chinese Academy of Sciences); Hassan Foroosh (University of Central Florida) <br />
            </p>

<p>
<b>194. <a href='../../wp-content/uploads/papers/0849-paper.pdf'> Deep Learning for Robust end-to-end Tone Mapping</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0849-supplementary.zip'>[Supplementary]</a> <br />
    Alexia Briassouli (Maastricht University); Rico Montulet (Maastricht University) <br />
            </p>

<p>
<b>195. <a href='../../wp-content/uploads/papers/1116-paper.pdf'> Base-detail image inpainting</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1116-supplementary.zip'>[Supplementary]</a> <br />
    Ruonan Zhang (Peng Cheng Laboratory); Yurui Ren (Shenzhen Graduate School, Peking University); Ge Li (SECE, Shenzhen Graduate School, Peking University); Jingfei Qiu (Peng Cheng Laboratory) <br />
            </p>

<p>
<b>196. <a href='../../wp-content/uploads/papers/1218-paper.html'> Generalised Visual Microphone</a></b>  <br />
    Juhyun Ahn (SUALAB) <br />
            </p>

<p>
<b>197. <a href='../../wp-content/uploads/papers/0160-paper.pdf'> Guide Your Eyes: Learning Image Manipulation under Saliency Guidance</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0160-supplementary.zip'>[Supplementary]</a> <br />
    Yen-Chung Chen (National Chiao Tung University); Keng-Jui Chang (National Chiao Tung University); Yi-Hsuan Tsai (NEC Labs America); Yu-Chiang Frank Wang (National Taiwan University); Wei-Chen Chiu (National Chiao Tung University) <br />
            </p>

<p>
<b>198. <a href='../../wp-content/uploads/papers/0168-paper.pdf'> Residual Multiscale Based Single Image Deraining</a></b>  <br />
    Yupei Zheng (Beijing Jiaotong University); Xin Yu (Australian National University); Miaomiao Liu (Australian National University); Shunli Zhang (Beijing Jiaotong University) <br />
            </p>

<p>
<b>199. <a href='../../wp-content/uploads/papers/0355-paper.pdf'> Learnable Gated Temporal Shift Module for Free-form Video Inpainting</a></b>  <br />
    Ya-Liang Chang (National Taiwan University); Zhe Yu Liu (National Taiwan University); Kuan-Ying Lee (National Taiwan University); Winston Hsu (National Taiwan University) <br />
            </p>

<p>
<b>200. <a href='../../wp-content/uploads/papers/0413-paper.pdf'> MS-GAN: Text to Image Synthesis with Attention-Modulated Generators and Similarity-aware Discriminators</a></b>  <br />
    Fengling Mao (Chinese Academy of Sciences ); Bingpeng Ma (Chinese Academy of Sciences); Hong Chang (Chinese Academy of Sciences); Shiguang Shan (Chinese Academy of Sciences); Xilin Chen (Chinese Academy of Sciences) <br />
            </p>

<p>
<b>201. <a href='../../wp-content/uploads/papers/0425-paper.pdf'> Element-Embedded Style Transfer Networks for Style Harmonization</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0425-supplementary.zip'>[Supplementary]</a> <br />
    Hwai-Jin Peng (National Taiwan University); Chia-Ming WANG (National Taiwan University); Yu-Chiang Frank Wang (National Taiwan University) <br />
            </p>

<p>
<b>202. <a href='../../wp-content/uploads/papers/0628-paper.pdf'> Harmonic Networks for Image Classification</a></b>  <br />
    Matej Ulicny (Trinity College Dublin); Vladimir Krylov (Trinity College Dublin); Rozenn Dahyot (Trinity College Dublin) <br />
            </p>

<p>
<b>203. <a href='../../wp-content/uploads/papers/0773-paper.pdf'> Semi-supervised Feature-Level Attribute Manipulation for Fashion Image Retrieval</a></b>  <br />
    Minchul Shin (Search Solutions Inc.); Sanghyuk Park (NAVER Clova Vision); Taeksoo Kim (Naver Corporation) <br />
            </p>

<p>
<b>204. <a href='../../wp-content/uploads/papers/0788-paper.pdf'> Fast and Multilevel Semantic-Preserving Discrete Hashing</a></b>  <br />
    Wanqian Zhang (Chinese Academy of Sciences); Dayan Wu (Chinese Academy of Sciences); Jing Liu (Chinese Academy of Sciences); Bo Li (Chinese Academy of Sciences); Xiaoyan Gu (Chinese Academy of Sciences); Weiping Wang (Chinese Academy of Sciences); Dan Meng (Chinese Academy of Sciences) <br />
            </p>

<p>
<b>205. <a href='../../wp-content/uploads/papers/1042-paper.pdf'> Blind Image Deconvolution using Pretrained Generative Priors</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1042-supplementary.zip'>[Supplementary]</a> <br />
    Muhammad Asim (Information Technology University, Lahore); Fahad Shamshad (Information Technology University, Lahore); Ali Ahmed (Information Technology University, Lahore) <br />
            </p>

<p>
<b>206. <a href='../../wp-content/uploads/papers/1119-paper.pdf'> Single Image Super-Resolution via CNN Architectures and TV-TV Minimization</a></b>  <br />
    Marija Vella (Heriot-Watt University); Joao F.C. Mota (Heriot-Watt University) <br />
            </p>

<p>
<b>207. <a href='../../wp-content/uploads/papers/1172-paper.pdf'> PtychoNet: Fast and High Quality Phase Retrieval for Ptychography</a></b>  <br />
    Ziqiao  Guan (Stony Brook University); Esther Tsai (Brookhaven National Laboratory); Xiaojing Huang (Brookhaven National Laboratory); Kevin Yager (Brookhaven National Laboratory); Hong Qin (Stony Brook University) <br />
            </p>

<p>
<b>208. <a href='../../wp-content/uploads/papers/0359-paper.pdf'> Texel-Att: Representing and Classifying Element-Based Textures by Attributes</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0359-supplementary.pdf'>[Supplementary]</a> <br />
    Marco Godi (University of Verona); Christian Joppi (University of Verona); Andrea Giachetti (University of Verona); Fabio Pellacini (Sapienza University of Rome); Marco Cristani (University of Verona) <br />
            </p>

<p>
<b>209. <a href='../../wp-content/uploads/papers/0703-paper.pdf'> Style-Guided Zero-Shot Sketch-based Image Retrieval</a></b>  <br />
    Titir Dutta (Indian Institute of Science, Bangalore); Soma Biswas (Indian Institute of Science, Bangalore) <br />
            </p>

<p>
<b>210. <a href='../../wp-content/uploads/papers/0165-paper.pdf'> Robust Synthesis of Adversarial Visual Examples Using a Deep Image Prior</a></b>  <br />
    Thomas Gittings (University of Surrey); Steve Schneider (University of Surrey); John Collomosse (University of Surrey) <br />
            </p>

<p>
<b>211. <a href='../../wp-content/uploads/papers/0328-paper.pdf'> Orthographic Feature Transform for Monocular 3D Object Detection</a></b>  <br />
    Thomas Roddick (University of Cambridge); Alex Kendall (University of Cambridge); Roberto Cipolla (University of Cambridge) <br />
            </p>

<p>
<b>212. <a href='../../wp-content/uploads/papers/0739-paper.pdf'> An Empirical Study on Leveraging Scene Graphs for Visual Question Answering</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0739-supplementary.pdf'>[Supplementary]</a> <br />
    Cheng Zhang (Ohio State University); Wei-Lun Chao (Cornell University); Dong Xuan (Ohio State University) <br />
            </p>

<p>
<b>213. <a href='../../wp-content/uploads/papers/0035-paper.pdf'> Generalized Zero-shot Learning using Open Set Recognition</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0035-supplementary.pdf'>[Supplementary]</a> <br />
    Omkar Gune (Indian Institute of Technology Bombay); Amit More (Indian Institute of Technology Bombay); Biplab Banerjee (Indian Institute of Technology Bombay); Subhasis Chaudhuri (Indian Institute of Technology Bombay) <br />
            </p>

<p>
<b>214. <a href='../../wp-content/uploads/papers/0144-paper.pdf'> High Frequency Residual Learning for Multi-Scale Image Classification</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0144-supplementary.pdf'>[Supplementary]</a> <br />
    Bowen Cheng (UIUC); Rong Xiao (Ping An); Jianfeng Wang (Microsoft Research); Thomas Huang (UIUC); Lei Zhang (Microsoft) <br />
            </p>

<p>
<b>215. <a href='../../wp-content/uploads/papers/0145-paper.pdf'> Learning Efficient Detector with Semi-supervised Adaptive Distillation</a></b>  <br />
    Shitao Tang (SenseTime Research); Litong Feng (SenseTime Research); Wenqi Shao (The Chinese University of HongKong); Zhanghui Kuang (SenseTime Ltd.); Wayne Zhang (SenseTime Research); Zheng Lu (University of Nottingham, Ningbo China) <br />
            </p>

<p>
<b>216. <a href='../../wp-content/uploads/papers/0198-paper.pdf'> Knowledge Distillation for End-to-End Person Search</a></b>  <br />
    Bharti Munjal (OSRAM); Fabio Galasso (OSRAM); Sikandar Amin (OSRAM) <br />
            </p>

<p>
<b>217. <a href='../../wp-content/uploads/papers/0209-paper.pdf'> One-Shot Scene-Specific Crowd Counting</a></b>  <br />
    Mohammad Hossain (HUAWEI Technologies Co, LTD.); Mahesh Kumar K (University of Manitoba); Mehrdad Hosseinzadeh (University of Manitoba); Omit Chanda (University of Manitoba); Yang Wang (University of Manitoba) <br />
            </p>

<p>
<b>218. <a href='../../wp-content/uploads/papers/0284-paper.pdf'> Exploring the Vulnerability of Single Shot Module in Object Detectors via Imperceptible Background Patches</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0284-supplementary.zip'>[Supplementary]</a> <br />
    Yuezun Li (University at Albany); Xiao Bian (GE Global Research); Ming-Ching Chang (University at Albany); Siwei Lyu (University at Albany) <br />
            </p>

<p>
<b>219. <a href='../../wp-content/uploads/papers/0289-paper.pdf'> Balancing Specialization, Generalization, and Compression for Detection and Tracking</a></b>  <br />
    Dotan Kaufman (Amazon); Koby Bibas (Amazon); Eran Borenstein (Amazon); Michael Chertok (Amazon, Lab126); Tal Hassner (Amazon) <br />
            </p>

<p>
<b>220. <a href='../../wp-content/uploads/papers/0334-paper.pdf'> Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0334-supplementary.zip'>[Supplementary]</a> <br />
    Hila Levi (Weizmann Institue of Science); Shimon Ullman (Weizmann Institute of Science) <br />
            </p>

<p>
<b>221. <a href='../../wp-content/uploads/papers/0347-paper.pdf'> Open-set Recognition of Unseen Macromolecules in Cellular Electron Cryo-Tomograms by Soft Large Margin Centralized Cosine Loss</a></b>  <br />
    Xuefeng Du (Xi&#x27;an Jiaotong University); Xiangrui Zeng (Carnegie Mellon University); Bo Zhou (Yale University); Alex Singh (Carnegie Mellon University); Min Xu (Carnegie Mellon University) <br />
            </p>

<p>
<b>222. <a href='../../wp-content/uploads/papers/0541-paper.pdf'> Multi-scale Template Matching with Scalable Diversity Similarity in an Unconstrained Environment</a></b>  <br />
    Yi Zhang (Iwate University); Chao Zhang (University of Fukui); Takuya Akashi (Iwate University) <br />
            </p>

<p>
<b>223. <a href='../../wp-content/uploads/papers/0545-paper.pdf'> Improving Multi-stage Object Detection via Iterative Proposal Refinement</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0545-supplementary.zip'>[Supplementary]</a> <br />
    Jicheng Gong (Westwell-lab); Zhao Zhao (Westwell-lab); Nic Li (Westwell-lab) <br />
            </p>

<p>
<b>224. <a href='../../wp-content/uploads/papers/0657-paper.pdf'> Generating Expensive Relationship Features from Cheap Objects</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0657-supplementary.zip'>[Supplementary]</a> <br />
    Xiaogang Wang (National University of Singapore); Qianru Sun (Singapore Management University); Marcelo Ang (National University of Singapore); Tat-Seng Chua (National University of Singapore) <br />
            </p>

<p>
<b>225. <a href='../../wp-content/uploads/papers/0662-paper.pdf'> Soft Sampling for Robust Object Detection</a></b>  <br />
    Zhe Wu (University of Maryland); Navaneeth Bodla (University of Maryland); Bharat Singh (Amazon); Mahyar Najibi (University of Maryland); Rama Chellappa (University of Maryland); Larry Davis (University of Maryland) <br />
            </p>

<p>
<b>226. <a href='../../wp-content/uploads/papers/0681-paper.pdf'> Joint Learning of Attended Zero-Shot Features and Visual-Semantic Mapping</a></b>  <br />
    Yanan Li (Zhejiang Lab); Donghui Wang (Zhejiang University) <br />
            </p>

<p>
<b>227. <a href='../../wp-content/uploads/papers/0809-paper.pdf'> Cascade RetinaNet: Maintaining Consistency for Single-Stage Object Detection</a></b>  <br />
    Hongkai Zhang (Chinese Academy of Sciences); Hong Chang (Chinese Academy of Sciences); Bingpeng Ma (Chinese Academy of Sciences); Shiguang Shan (Chinese Academy of Sciences); Xilin Chen (Chinese Academy of Sciences) <br />
            </p>

<p>
<b>228. <a href='../../wp-content/uploads/papers/0847-paper.pdf'> Deep Learning Fusion of RGB and Depth Images for Pedestrian Detection</a></b>  <br />
    Zhixin Guo (Ghent University); Wenzhi Liao (Ghent University); Yifan Xiao (Ghent University); Peter Veelaert (UGent); Wilfried Philips (IPI &#8211; Ghent University &#8211; imec) <br />
            </p>

<p>
<b>229. <a href='../../wp-content/uploads/papers/0908-paper.pdf'> BMNet: A Reconstructed Network for Lightweight Object Detection via Branch Merging</a></b>  <br />
    Hefei Ling (Huazhong University of Science and Technology); Li Zhang (Huazhong University of Science and Technology); Yangyang Qin (Huazhong University of Science and Technology); Yuxuan Shi (Huazhong University of Science and Technology); Lei Wu (Huazhong University of Science and Technology); Jiazhong Chen (Huazhong University of Science and Technology); Baiyan Zhang (Huazhong University of Science and Technology) <br />
            </p>

<p>
<b>230. <a href='../../wp-content/uploads/papers/0921-paper.pdf'> An Adaptive Supervision Framework for Active Learning in Object Detection</a></b>  <br />
    Sai Vikas Desai (Indian Institute of Technology, Hyderabad); Akshay Chandra Lagandula (Indian Institute Of Technology, Hyderabad); Wei Guo (The University of Tokyo); Seishi Ninomiya (The University of Tokyo); Vineeth N Balasubramanian (Indian Institute of Technology, Hyderabad) <br />
            </p>

<p>
<b>231. <a href='../../wp-content/uploads/papers/1017-paper.pdf'> Adversarial Signboard against Object Detector</a></b>  <br />
    Yi Huang (Nanyang Technological University); Kwok-Yan Lam (Nanyang Technological University); Wai-Kin Adams Kong (Nanyang Technological University) <br />
            </p>

<p>
<b>232. <a href='../../wp-content/uploads/papers/1038-paper.pdf'> Domain Adaptation for Object Detection via Style Consistency</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1038-supplementary.pdf'>[Supplementary]</a> <br />
    Adrian Lopez Rodriguez (Imperial College London); Krystian Mikolajczyk (Imperial College London) <br />
            </p>

<p>
<b>233. <a href='../../wp-content/uploads/papers/1044-paper.pdf'> HydraPicker: Fully Automated Particle Picking in Cryo-EM by Utilizing Dataset Bias in Single Shot Detection</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1044-supplementary.zip'>[Supplementary]</a> <br />
    Abbas Masoumzadeh (York University); Marcus Brubaker (York University) <br />
            </p>

<p>
<b>234. <a href='../../wp-content/uploads/papers/1057-paper.pdf'> Rethinking Convolutional Feature Extraction for Small Object Detection</a></b>  <br />
    Burhan Mudassar (Georgia Institute of Technology); Saibal Mukhopadhyay (Georgia Institute of Technology) <br />
            </p>

<p>
<b>235. <a href='../../wp-content/uploads/papers/0061-paper.pdf'> Guided Zoom: Questioning Network Evidence for Fine-grained Classification</a></b>  <br />
    Sarah Bargal (Boston University); Andrea Zunino (Istituto Italiano di Tecnologia); Vitali Petsiuk (Boston University); Jianming Zhang (Adobe Research); Kate Saenko (Boston University); Vittorio Murino (Istituto Italiano di Tecnologia); Stan Sclaroff (Boston University) <br />
            </p>

<p>
<b>236. <a href='../../wp-content/uploads/papers/0218-paper.pdf'> Geometry-Aware Video Object Detection for Static Cameras</a></b>  <br />
    Dan Xu (University of Oxford); Weidi Xie (University of Oxford); Andrew Zisserman (University of Oxford) <br />
            </p>

<p>
<b>237. <a href='../../wp-content/uploads/papers/0550-paper.pdf'> PCAS: Pruning Channels with Attention Statistics for Deep Network Compression</a></b>  <br />
    Kohei Yamamoto (Oki Electric Industry Co., Ltd.); Kurato Maeno (Oki Electric Industry Co., Ltd.) <br />
            </p>

<p>
<b>238. <a href='../../wp-content/uploads/papers/0636-paper.pdf'> Large Margin In Softmax Cross-Entropy Loss</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0636-supplementary.zip'>[Supplementary]</a> <br />
    Takumi Kobayashi (National Institute of Advanced Industrial Science and Technology) <br />
            </p>

<p>
<b>239. <a href='../../wp-content/uploads/papers/0885-paper.pdf'> Group Based Deep Shared Feature Learning for Fine-grained Image Classification</a></b>  <br />
    Xuelu Li (The Pennsylvania State University); Vishal Monga (Pennsylvania State University) <br />
            </p>

<p>
<b>240. <a href='../../wp-content/uploads/papers/0041-paper.pdf'> A Top-Down Unified Framework for Instance-level Human Parsing</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0041-supplementary.zip'>[Supplementary]</a> <br />
    Haifang Qin (Peking University); Weixiang Hong (National University of Singapore); Wei-Chih Hung (University of California, Merced); Yi-Hsuan Tsai (NEC Labs America); Ming-Hsuan Yang (University of California, Merced) <br />
            </p>

<p>
<b>241. <a href='../../wp-content/uploads/papers/0085-paper.pdf'> Rethinking Classification and Localization for Cascade R-CNN</a></b>  <br />
    Ang Li (Nanjing University of Science and Technology); Xue Yang (Shanghai Jiao Tong University); Chongyang Zhang (Nanjing University of Science and Technology) <br />
            </p>

<p>
<b>242. <a href='../../wp-content/uploads/papers/0124-paper.pdf'> Image Captioning with Unseen Objects</a></b>  <br />
    Berkan Demirel (HAVELSAN Inc. &amp; METU); Ramazan Gokberk Cinbis (METU); Nazli Ikizler-Cinbis (Hacettepe University) <br />
            </p>

<p>
<b>243. <a href='../../wp-content/uploads/papers/0398-paper.pdf'> Spatially and Temporally Efficient Non-local Attention Network for Video-based Person Re-Identification</a></b>  <br />
    Chih-Ting Liu (National Taiwan University); Chih-Wei Wu (National Taiwan University); Yu-Chiang Frank Wang (National Taiwan University); Shao-Yi Chien (National Taiwan University) <br />
            </p>

<p>
<b>244. <a href='../../wp-content/uploads/papers/0432-paper.pdf'> Global Aggregation then Local Distribution in Fully Convolutional Networks</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0432-supplementary.zip'>[Supplementary]</a> <br />
    Xiangtai Li (Peking University); Li Zhang (University of Oxford); Ansheng You (Peking University); Maoke Yang (DeepMotion); Yunhai Tong (Peking University); Kuiyuan Yang (DeepMotion) <br />
            </p>

<p>
<b>245. <a href='../../wp-content/uploads/papers/0466-paper.pdf'> ClueNet : A Deep Framework for Occluded Pedestrian Pose Estimation</a></b>  <br />
    Perla Sai Raj Kishore (Institute of Engineering &amp; Management); Sudip Das (Indian Statistical Institute); Partha Sarathi Mukherjee (Indian Statistical Institute); Ujjwal Bhattacharya (ISI Kolkata) <br />
            </p>

<p>
<b>246. <a href='../../wp-content/uploads/papers/0474-paper.pdf'> AutoCorrect: Deep Inductive Alignment of Noisy Geometric Annotations</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0474-supplementary.pdf'>[Supplementary]</a> <br />
    Honglie Chen (University of Oxford); Weidi Xie (University of Oxford); Andrea Vedaldi (University of Oxford); Andrew Zisserman (University of Oxford) <br />
            </p>

<p>
<b>247. <a href='../../wp-content/uploads/papers/0663-paper.pdf'> Improving Object Detection from Scratch via Gated Feature Reuse</a></b>  <br />
    Zhiqiang Shen (Carnegie Mellon University); Honghui Shi (IBM, UIUC); Jiahui Yu (UIUC); Hai Phan (Carnegie Mellon University); Rogerio Feris (IBM Research AI, MIT-IBM Watson AI Lab); Liangliang Cao (HelloVera); Ding Liu (UIUC); Xinchao Wang (Stevens Institute of Technology); Thomas Huang (UIUC); Marios Savvides (Carnegie Mellon University) <br />
            </p>

<p>
<b>248. <a href='../../wp-content/uploads/papers/0839-paper.pdf'> Mining Discriminative Food Regions for Accurate Food Recognition</a></b>  <br />
    Jianing Qiu (Imperial College London); Po Wen Lo (Imperial College London); Yingnan Sun (Imperial College London); Siyao Wang (Imperial College London); Benny Lo (Imperial College London) <br />
            </p>

<p>
<b>249. <a href='../../wp-content/uploads/papers/1016-paper.pdf'> Meta Learning for Unsupervised Clustering</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1016-supplementary.zip'>[Supplementary]</a> <br />
    Han-Ul Kim (Korea University); Yeong Jun Koh (Chungnam National University); Chang-Su Kim (Korea University) <br />
            </p>

<p>
<b>250. <a href='../../wp-content/uploads/papers/1082-paper.pdf'> Enhanced 3D convolutional networks for crowd counting</a></b>  <br />
    Zhikang Zou (Huazhong University of Science and Technology); Huiliang Shao (Huazhong University of Science and Technology); Xiaoye Qu (Huazhong University of Science and Technology); Wei Wei (Huazhong University of Science and Technology); Pan Zhou (Huazhong University of Science and Technology) <br />
            </p>

<p>
<b>251. <a href='../../wp-content/uploads/papers/1186-paper.pdf'> Image Classification with Hierarchical Multigraph Networks</a></b>  <br />
    Boris Knyazev (University of Guelph); Xiao Lin (SRI International); Mohamed Amer (RobustAI); Graham Taylor (University of Guelph) <br />
            </p>

<p>
<b>252. <a href='../../wp-content/uploads/papers/0221-paper.pdf'> Towards Weakly Supervised Semantic Segmentation in 3D Graph-Structured Point Clouds of Wild Scenes</a></b>  <br />
    Haiyan Wang (City University of New York); Xuejian Rong (City University of New York); Liang Yang (City University of New York); YingLi Tian (City University of New York) <br />
            </p>

<p>
<b>253. <a href='../../wp-content/uploads/papers/0959-paper.pdf'> Fast-SCNN: Fast Semantic Segmentation Network</a></b>  <br />
    Rudra Poudel (Tosihiba Research Europe, Ltd.); Stephan Liwicki (Toshiba Research Europe, Ltd.); Roberto Cipolla (University of Cambridge) <br />
            </p>

<p>
<b>254. <a href='../../wp-content/uploads/papers/0089-paper.pdf'> Dual Graph Convolutional Network for Semantic Segmentation</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0089-supplementary.zip'>[Supplementary]</a> <br />
    Li Zhang (University of Oxford); Xiangtai Li (Peking University); Anurag Arnab (University of Oxford); Kuiyuan Yang (DeepMotion); Yunhai Tong (Peking University); Philip Torr (University of Oxford) <br />
            </p>

<p>
<b>255. <a href='../../wp-content/uploads/papers/0112-paper.pdf'> Where are the Masks: Instance Segmentation with Image-level Supervision</a></b>  <br />
    Issam Hadj Laradji (University of British Columbia); David Vazquez (Element AI); Mark Schmidt (University of British Columbia) <br />
            </p>

<p>
<b>256. <a href='../../wp-content/uploads/papers/0175-paper.pdf'> Geometry-Aware End-to-End Skeleton Detection</a></b>  <br />
    Weijian Xu (University of California, San Diego); Gaurav Parmar (University of California, San Diego); Zhuowen Tu (University of California, San Diego) <br />
            </p>

<p>
<b>257. <a href='../../wp-content/uploads/papers/0649-paper.pdf'> Adaptive Compression-based Lifelong Learning</a></b>  <br />
    Shivangi Srivastava (Wageningen University and Research); Maxim Berman (KU Leuven); Matthew Blaschko (KU Leuven); Devis Tuia (Wageningen University and Research) <br />
            </p>

<p>
<b>258. <a href='../../wp-content/uploads/papers/0874-paper.pdf'> Working Hands: A Hand-Tool Assembly Dataset for Image Segmentation and Activity Mining</a></b>  <br />
    Roy Shilkrot (Stony Brook University); Supreeth Narasimhaswamy (Stony Brook University); Saif Vazir (Stony Brook University); Minh Hoai Nguyen (Stony Brook University) <br />
            </p>

<p>
<b>259. <a href='../../wp-content/uploads/papers/0955-paper.pdf'> DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation</a></b>  <br />
    Gen Li (Sungkyunkwan University); Joongkyu Kim (Sungkyunkwan University) <br />
            </p>

<p>
<b>260. <a href='../../wp-content/uploads/papers/1031-paper.pdf'> Feature Pyramid Encoding Network for Real-time Semantic Segmentation</a></b>  <br />
    Mengyu Liu (University of Manchester); Hujun Yin (University of Manchester) <br />
            </p>

<p>
<b>261. <a href='../../wp-content/uploads/papers/0865-paper.pdf'> Convolutional CRFs for Semantic Segmentation</a></b>  <br />
    Marvin Teichmann (University of Cambridge); Roberto Cipolla (University of Cambridge) <br />
            </p>

<p>
<b>262. <a href='../../wp-content/uploads/papers/0002-paper.pdf'> Visuomotor Understanding for Representation Learning of Driving Scenes</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0002-supplementary.zip'>[Supplementary]</a> <br />
    Seokju Lee (Korea Advanced Institute of Science and Technology); Junsik Kim (Korea Advanced Institute of Science and Technology); Tae-Hyun Oh (MIT CSAIL); Yongseop Jeong (Korea Advanced Institute of Science and Technology); Donggeun Yoo (Lunit); Stephen Lin (Microsoft Research); In So Kweon (Korea Advanced Institute of Science and Technology) <br />
            </p>

<p>
<b>263. <a href='../../wp-content/uploads/papers/0196-paper.pdf'> Referring Expression Object Segmentation with Caption-Aware Consistency</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0196-supplementary.pdf'>[Supplementary]</a> <br />
    Yi-Wen Chen (Academia Sinica); Yi-Hsuan Tsai (NEC Labs America); Tiantian Wang (University of California at Merced); Yen-Yu Lin (Academia Sinica); Ming-Hsuan Yang (University of California at Merced) <br />
            </p>

<p>
<b>264. <a href='../../wp-content/uploads/papers/0459-paper.pdf'> Dispersion based Clustering for Unsupervised Person Re-identification</a></b>  <br />
    Guodong Ding (Nanjing University of Science and Technology); Salman Khan (Australian National University (ANU)); Zhenmin Tang (Nanjing University of Science and Technology) <br />
            </p>

<p>
<b>265. <a href='../../wp-content/uploads/papers/0677-paper.pdf'> Oval Shape Constraint based Optic Disc and Cup Segmentation in Fundus Photographs</a></b>  <br />
    Jun Wu (Northwestern Polytechnical University); Kaiwei Wang (Northwestern Polytechnical University); Zongjiang Shang (Northwestern Polytechnical University); Jie Xu (Beijing Tongren Hospital); Dayong Ding (Vistel Inc.); Xirong Li (Renmin University of China); Gang Yang (Renmin University of China) <br />
            </p>

<p>
<b>266. <a href='../../wp-content/uploads/papers/0984-paper.pdf'> An end-to-end deep learning approach for simultaneous background modeling and subtraction</a></b>  <br />
    Víctor Mondéjar-Guerra (UDC); Jorge Novo (University of A Coruña); José Rouco (University of A Coruña); Marcos Ortega (University of A Coruña) <br />
            </p>

<p>
<b>267. <a href='../../wp-content/uploads/papers/0269-paper.pdf'> Spatio-temporal Relational Reasoning for Video Question Answering</a></b>  <br />
    Gursimran Singh (University of British Columbia); Leonid Sigal (University of British Columbia); Jim Little (University of British Columbia) <br />
            </p>

<p>
<b>268. <a href='../../wp-content/uploads/papers/0336-paper.pdf'> Mutual Suppression Network for Video Prediction using Disentangled Features</a></b>  <br />
    Jungbeom Lee (Seoul National University); Jangho Lee (Seoul National University); Sungmin Lee (Seoul National University); Sungroh Yoon (Seoul National University) <br />
            </p>

<p>
<b>269. <a href='../../wp-content/uploads/papers/0016-paper.pdf'> Learning Spatio-Temporal Features with Two-Stream Deep 3D CNNs for Lipreading</a></b>  <br />
    Xinshuo Weng (Carnegie Mellon University); Kris Kitani (Carnegie Mellon University) <br />
            </p>

<p>
<b>270. <a href='../../wp-content/uploads/papers/0129-paper.pdf'> Motion-Aware Feature for Improved Video Anomaly Detection</a></b>  <br />
    Yi Zhu (University of California, Merced); Shawn Newsam (University of California, Merced) <br />
            </p>

<p>
<b>271. <a href='../../wp-content/uploads/papers/0491-paper.pdf'> Attention-based Facial Behavior Analytics inSocial Communication</a></b>  <br />
    Lezi Wang (Rutgers University); Chongyang Bai (Dartmouth College); Maksim Bolonkin (Dartmouth College); VS Subrahmanian (Dartmouth College); Judee Burgoon (University of Arizona); Norah Dunbar (University of California, Santa Babara); Dimitris Metaxas (Rutgers University) <br />
            </p>

<p>
<b>272. <a href='../../wp-content/uploads/papers/0697-paper.pdf'> Searching for Ambiguous Objects in Videos using Relational Referring Expressions</a></b>  <br />
    Hazan Anayurt (Middle East Technical University); Sezai Artun Ozyegin (Middle East Technical University); Ulfet Cetin (Middle East Technical University); Utku Aktas (Middle East Technical University); Sinan Kalkan (Middle East Technical University) <br />
            </p>

<p>
<b>273. <a href='../../wp-content/uploads/papers/0726-paper.pdf'> Hybrid Deep Network for Anomaly Detection</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0726-supplementary.zip'>[Supplementary]</a> <br />
    Trong Nguyen Nguyen (University of Montreal); Jean Meunier (University of Montreal) <br />
            </p>

<p>
<b>274. <a href='../../wp-content/uploads/papers/0966-paper.pdf'> VStegNET: Video Steganography Network using Spatio-Temporal features and Micro-Bottleneck</a></b>  <br />
    Suraj Kumar (Aligarh Muslim University); Aayush Mishra (IIT Mandi); Saiful Islam (Aligarh Muslim University); Aditya Nigam (IIT Mandi) <br />
            </p>

<p>
<b>275. <a href='../../wp-content/uploads/papers/1023-paper.pdf'> Order Matters: Shuffling Sequence Generation for Video Prediction</a></b>  <br />
    Junyan Wang (Newcastle University); BingZhang Hu (Newcastle University); Yang Long (Newcastle University); Yu Guan (Newcastle University) <br />
            </p>

<p>
<b>276. <a href='../../wp-content/uploads/papers/1211-paper.pdf'> Multi-Grained Spatio-temporal Modeling for Lip-reading</a></b>  <br />
    Chenhao Wang (Institute of Computing Technology, Chinese Academy of Sciences) <br />
            </p>

<p>
<b>277. <a href='../../wp-content/uploads/papers/0186-paper.pdf'> Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks</a></b>  <br />
    Zitong Yu (CMVS, University of Oulu); Xiaobai Li (University of Oulu); Guoying Zhao (University of Oulu) <br />
            </p>

<p>
<b>278. <a href='../../wp-content/uploads/papers/0332-paper.pdf'> Spatio-Temporal Associative Representation for Video Person Re-Identification</a></b>  <br />
    Guile Wu (Queen Mary University of London); Xiatian Zhu (Samsung AI Centre, Cambridge); Shaogang Gong (Queen Mary University of London) <br />
            </p>

<p>
<b>279. <a href='../../wp-content/uploads/papers/0363-paper.pdf'> Use What You Have: Video retrieval using representations from collaborative experts</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0363-supplementary.pdf'>[Supplementary]</a> <br />
    Yang Liu (University of Oxford); Samuel Albanie (University of Oxford); Arsha Nagrani (University of Oxford); Andrew Zisserman (University of Oxford) <br />
            </p>

<p>
<b>280. <a href='../../wp-content/uploads/papers/1125-paper.pdf'> VideoNavQA: Bridging the Gap between Visual and Embodied Question Answering</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1125-supplementary.zip'>[Supplementary]</a> <br />
    Catalina Cangea (University of Cambridge); Eugene Belilovsky (Mila); Aaron Courville (Universite de Montreal) <br />
            </p>

<p>
<b>281. <a href='../../wp-content/uploads/papers/1103-paper.pdf'> MLGCN: Multi-Laplacian Graph Convolutional Networks for Human Action Recognition</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1103-supplementary.pdf'>[Supplementary]</a> <br />
    Ahmed Mazari (Sorbonne Universite); Hichem Sahbi (Sorbonne University) <br />
            </p>

</div>
</div>
<div>
<p>
<b>16:15 &#8212; 18:15 &nbsp;&nbsp;Oral Presentations: Objects, Segmentation, Textures, and Colours</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p>Chair: Roy Davies <br />Sponsored by Apple</p>
</div>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_8'>
<p>
<b>282. <a href='../../wp-content/uploads/papers/0105-paper.pdf'> Sensor-Independent Illumination Estimation for DNN Models</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0105-supplementary.zip'>[Supplementary]</a> <br />
    Mahmoud Afifi (York University); Michael Brown (York University) <br />
            </p>

<p>
<b>283. <a href='../../wp-content/uploads/papers/0165-paper.pdf'> Robust Synthesis of Adversarial Visual Examples Using a Deep Image Prior</a></b>  <br />
    Thomas Gittings (University of Surrey); Steve Schneider (University of Surrey); John Collomosse (University of Surrey) <br />
            </p>

<p>
<b>284. <a href='../../wp-content/uploads/papers/0221-paper.pdf'> Towards Weakly Supervised Semantic Segmentation in 3D Graph-Structured Point Clouds of Wild Scenes</a></b>  <br />
    Haiyan Wang (City University of New York); Xuejian Rong (City University of New York); Liang Yang (City University of New York); YingLi Tian (City University of New York) <br />
            </p>

<p>
<b>285. <a href='../../wp-content/uploads/papers/0328-paper.pdf'> Orthographic Feature Transform for Monocular 3D Object Detection</a></b>  <br />
    Thomas Roddick (University of Cambridge); Alex Kendall (University of Cambridge); Roberto Cipolla (University of Cambridge) <br />
            </p>

<p>
<b>286. <a href='../../wp-content/uploads/papers/0359-paper.pdf'> Texel-Att: Representing and Classifying Element-Based Textures by Attributes</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0359-supplementary.pdf'>[Supplementary]</a> <br />
    Marco Godi (University of Verona); Christian Joppi (University of Verona); Andrea Giachetti (University of Verona); Fabio Pellacini (Sapienza University of Rome); Marco Cristani (University of Verona) <br />
            </p>

<p>
<b>287. <a href='../../wp-content/uploads/papers/0721-paper.pdf'> Content and Colour Distillation for Learning Image Translations with the Spatial Profile Loss</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0721-supplementary.pdf'>[Supplementary]</a> <br />
    Saquib Sarfraz (Karlsruhe Institute of Technology); Constantin Seibold (Karlsruhe Institute of Technology); Haroon Khalid (Karlsruhe Institute of Technology); Rainer Stiefelhagen (Karlsruhe Institute of Technology) <br />
            </p>

<p>
<b>288. <a href='../../wp-content/uploads/papers/0739-paper.pdf'> An Empirical Study on Leveraging Scene Graphs for Visual Question Answering</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0739-supplementary.pdf'>[Supplementary]</a> <br />
    Cheng Zhang (Ohio State University); Wei-Lun Chao (Cornell University); Dong Xuan (Ohio State University) <br />
            </p>

<p>
<b>289. <a href='../../wp-content/uploads/papers/0959-paper.pdf'> Fast-SCNN: Fast Semantic Segmentation Network</a></b>  <br />
    Rudra Poudel (Tosihiba Research Europe, Ltd.); Stephan Liwicki (Toshiba Research Europe, Ltd.); Roberto Cipolla (University of Cambridge) <br />
            </p>

</div>
</div>
<div>
<p>
<b>19:00 &#8212; late &nbsp;&nbsp;Banquet</b>
<i>National Museum Cardiff</i>
</p>
</div>
<hr />
<h2>Thursday 12<sup>th</sup> September</h2>
<div>
<p>
<b>08:00 &#8212; 09:00 &nbsp;&nbsp;Registration</b>
</p>
</div>
<div>
<p>
<b>09:00 &#8212; 10:00 &nbsp;&nbsp;Keynote</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p><b>Dissecting Neural Nets</b><br />Prof. Antonio Torralba (MIT)<br />Sponsored by Amazon</p>
</div>
</p>
</div>
<div>
<p>
<b>10:00 &#8212; 11:00 &nbsp;&nbsp;Oral Presentations: Motion and Flow</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p>Chair: Dave Marshall <br />Sponsored by Huawei</p>
</div>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_9'>
<p>
<b>290. <a href='../../wp-content/uploads/papers/0416-paper.pdf'> Relation-aware Multiple Attention Siamese Networks for Robust Visual Tracking</a></b>  <br />
    Fangyi Zhang (Chinese Academy of Sciences); Bingpeng Ma (Chinese Academy of Sciences); Hong Chang (Chinese Academy of Sciences); Shiguang Shan (Chinese Academy of Sciences); Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences) <br />
            </p>

<p>
<b>291. <a href='../../wp-content/uploads/papers/0589-paper.pdf'> Spatial Transformer Spectral Kernels for Deformable Image Registration</a></b>  <br />
    Ebrahim Al Safadi (Oregon Health and Science University); Xubo Song (Oregon Health and Science University) <br />
            </p>

<p>
<b>292. <a href='../../wp-content/uploads/papers/1003-paper.pdf'> Tracking the Known and the Unknown by Leveraging Semantic Information</a></b>  <br />
    Ardhendu Shekhar Tripathi (ETH Zurich); Martin Danelljan (ETH Zurich); Luc Van Gool (ETH Zurich); Radu Timofte (ETH Zurich) <br />
            </p>

<p>
<b>293. <a href='../../wp-content/uploads/papers/1065-paper.pdf'> Tracking Holistic Object Representations</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/1065-supplementary.pdf'>[Supplementary]</a> <br />
    Axel Sauer (Technical University of Munich); Elie Aljalbout (Technical University of Munich); Sami Haddadin (Technical University of Munich) <br />
            </p>-->

</div>
</div>
<div>
<p>
<b>11:00 &#8212; 11:45 &nbsp;&nbsp;Tea Break</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>11:45 &#8212; 13:15 &nbsp;&nbsp;Oral Presentations: Video Analysis</b>
<i>Sir Martin Evans Building</i>
<div style="margin-left:40px; padding-top: 0px">
<p>Chair: Paul Rosin <br />Sponsored by Intel</p>
</div>
</p>
<div style="margin-left:40px; padding-top: 0px">
<div id='session_10'>
<p>
<b>294. <a href='../../wp-content/uploads/papers/0218-paper.pdf'> Geometry-Aware Video Object Detection for Static Cameras</a></b>  <br />
    Dan Xu (University of Oxford); Weidi Xie (University of Oxford); Andrew Zisserman (University of Oxford) <br />
            </p>

<p>
<b>295. <a href='../../wp-content/uploads/papers/0269-paper.pdf'> Spatio-temporal Relational Reasoning for Video Question Answering</a></b>  <br />
    Gursimran Singh (University of British Columbia); Leonid Sigal (University of British Columbia); Jim Little (University of British Columbia) <br />
            </p>

<p>
<b>296. <a href='../../wp-content/uploads/papers/0336-paper.pdf'> Mutual Suppression Network for Video Prediction using Disentangled Features</a></b>  <br />
    Jungbeom Lee (Seoul National University); Jangho Lee (Seoul National University); Sungmin Lee (Seoul National University); Sungroh Yoon (Seoul National University) <br />
            </p>

<p>
<b>297. <a href='../../wp-content/uploads/papers/0399-paper.pdf'> Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace</a></b>  <br />
    Dimitrios Kollias (Imperial College London); Stefanos Zafeiriou (Imperial College London) <br />
            </p>

<p>
<b>298. <a href='../../wp-content/uploads/papers/0585-paper.pdf'> Forecasting Future Action Sequences with Neural Memory Networks</a></b> <br /><a style='font-size: 12px' href='../../wp-content/uploads/papers/0585-supplementary.zip'>[Supplementary]</a> <br />
    Harshala Gammulle (Queensland University of Technology); Simon Denman (Queensland University of Technology); Sridha Sridharan (Queensland University of Technology); Clinton Fookes (Queensland University of Technology) <br />
            </p>

<p>
<b>299. <a href='../../wp-content/uploads/papers/0599-paper.pdf'> Self-supervised Video Representation Learning for Correspondence Flow</a></b>  <br />
    Zihang Lai (University of Oxford); Weidi Xie (University of Oxford) <br />
            </p>

</div>
</div>
<div>
<p>
<b>13:15 &#8212; 14:00 &nbsp;&nbsp;Lunch</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>14:00 &#8212; 15:45 &nbsp;&nbsp;Workshops</b>
<i>Sir Martin Evans Building</i>
</p>
</div>
<div>
<p>
<b>15:45 &#8212; 16:30 &nbsp;&nbsp;Tea Break</b>
<i>SU, Great Hall</i>
</p>
</div>
<div>
<p>
<b>16:30 &#8212; 18:00 &nbsp;&nbsp;Workshops</b>
<i>Sir Martin Evans Building</i>
</p>
</div>
			</div>
					</div>
	</article>
		</div>
	</div>
						<footer class="footer footer-black footer-big">
						<div class="container">
																<div class="hestia-bottom-footer-content"><ul id="menu-footer" class="footer-menu pull-left"><li id="menu-item-374" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-374"><a href="../../index.html">Home</a></li>
<li id="menu-item-375" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-375"><a href="../../dates/index.html">Dates</a></li>
<li id="menu-item-376" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-376"><a href="../../attending/travel-info/index.html">Travel Info</a></li>
<li id="menu-item-378" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-378"><a href="../../people/organisers-2/index.html">Organisers</a></li>
</ul>					<div class="copyright pull-right">
				<a href="https://themeisle.com/" rel="nofollow">Hestia</a> | Logo by <a href="http://www.aylwyn.co.uk/">Aylwyn Bowen</a>			</div>
			</div>			</div>
					</footer>
				</div>
	</div>
 <script>
jQuery('.hestia-top-bar').replaceWith('<div class="hestia-top-bar" style="z-index: 9999; width: 100%; background: rgb(190, 14, 56);"><div id="tpbr_box" style="line-height:40px; font-size:15px; font-family: Helvetica, Arial, sans-serif; text-align:center; width:100%; color:white; font-weight:300;">Workshop submissions are now open!<a id="tpbr_calltoaction" style="background:#9f0019; display:inline-block; padding:2px 10px 1px; color:white; text-decoration:none; margin: 0px 20px 0px;border-radius:3px; line-height:28px;" href="../../workshops/index.html">Browse Workshops</a></div></div>');
<!-- update header -->
</script>		<button class="hestia-scroll-to-top">
			<i class="fa fa-angle-double-up" aria-hidden="true"></i>
		</button>
		<script type='text/javascript'>
/* <![CDATA[ */
var ctcc_vars = {"expiry":"30","method":"1","version":"1"};
/* ]]> */
</script>
<script type='text/javascript' src='../../wp-content/plugins/uk-cookie-consent/assets/js/uk-cookie-consent-jsa1ec.js?ver=2.3.0'></script>
<script type='text/javascript' src='../../wp-includes/js/comment-reply.min5010.js?ver=4.9.8'></script>
<script type='text/javascript' src='../../wp-content/themes/hestia/assets/bootstrap/js/bootstrap.min20b9.js?ver=1.0.2'></script>
<script type='text/javascript' src='../../wp-includes/js/jquery/ui/core.mine899.js?ver=1.11.4'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var requestpost = {"ajaxurl":"https:\/\/bmvc2019.org\/wp-admin\/admin-ajax.php","disable_autoslide":"","masonry":""};
/* ]]> */
</script>
<script type='text/javascript' src='../../wp-content/themes/hestia/assets/js/script.min747d.js?ver=2.4.5'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var wpgdprcData = {"ajaxURL":"https:\/\/bmvc2019.org\/wp-admin\/admin-ajax.php","ajaxSecurity":"9b7c823d14","isMultisite":"","path":"\/","blogId":""};
/* ]]> */
</script>
<script type='text/javascript' src='../../wp-content/plugins/wp-gdpr-compliance/assets/js/front004f.js?ver=1562162887'></script>
<script type='text/javascript' src='../../wp-includes/js/wp-embed.min5010.js?ver=4.9.8'></script>
			
				<script type="text/javascript">
					jQuery(document).ready(function($){
												if(!catapultReadCookie("catAccCookies")){ // If the cookie has not been set then show the bar
							$("html").addClass("has-cookie-bar");
							$("html").addClass("cookie-bar-bottom-bar");
							$("html").addClass("cookie-bar-bar");
													}
																	});
				</script>
			
			<div id="catapult-cookie-bar" class=""><div class="ctcc-inner "><span class="ctcc-left-side">This site uses cookies:  <a class="ctcc-more-info-link" tabindex=0 target="_blank" href="../../cookie-policy/index.html">Find out more.</a></span><span class="ctcc-right-side"><button id="catapultCookie" tabindex=0 onclick="catapultAcceptCookies();">Okay, thank you</button></span></div><!-- custom wrapper class --></div><!-- #catapult-cookie-bar --></body>

<!-- Mirrored from bmvc2019.org/programme/detailed-programme/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 25 Feb 2020 10:10:27 GMT -->
</html>
